{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking a look at the Enron labeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code borrowed from :\n",
    "https://github.com/shoreason/enron-topic-modeling/blob/master/enron_lda.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import vocab as vocabulary\n",
    "import collections\n",
    "import utils\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "# from wordcloud import WordCloud ,STOPWORDS\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import fileinput\n",
    "import shutil\n",
    "import os,sys,inspect\n",
    "import time\n",
    "# import markdown\n",
    "import json\n",
    "import requests\n",
    "import warnings\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install langdetect\n",
    "# from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "import googleapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PerspectiveAPI = googleapi.GOOGLEAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/data/SuperMod/emails.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrondata = pd.read_csv(datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                            message\n",
       "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
       "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
       "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
       "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrondata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_message(raw_message):\n",
    "    lines = raw_message.split('\\n')\n",
    "    email = {}\n",
    "    message = ''\n",
    "    keys_to_extract = ['from', 'to']\n",
    "    for line in lines:\n",
    "        if ':' not in line:\n",
    "            message += line.strip()\n",
    "            email['body'] = message\n",
    "        else:\n",
    "            pairs = line.split(':')\n",
    "            key = pairs[0].lower()\n",
    "            val = pairs[1].strip()\n",
    "            if key in keys_to_extract:\n",
    "                email[key] = val\n",
    "    return email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_into_emails(messages):\n",
    "    emails = [parse_raw_message(message) for message in messages]\n",
    "    return {\n",
    "        'body': map_to_list(emails, 'body'),\n",
    "        'to': map_to_list(emails, 'to'),\n",
    "        'from_': map_to_list(emails, 'from')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_list(emails, key):\n",
    "    results = []\n",
    "    for email in emails:\n",
    "        if key not in email:\n",
    "            results.append('')\n",
    "        else:\n",
    "            results.append(email[key])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                body                       to  \\\n",
      "0                               Here is our forecast     tim.belden@enron.com   \n",
      "1  Traveling to have a business meeting takes the...  john.lavorato@enron.com   \n",
      "2                     test successful.  way to go!!!   leah.arsdall@enron.com   \n",
      "3  Randy,Can you send me a schedule of the salary...    randall.gay@enron.com   \n",
      "4                                                        greg.piper@enron.com   \n",
      "\n",
      "                     from_  \n",
      "0  phillip.allen@enron.com  \n",
      "1  phillip.allen@enron.com  \n",
      "2  phillip.allen@enron.com  \n",
      "3  phillip.allen@enron.com  \n",
      "4  phillip.allen@enron.com  \n"
     ]
    }
   ],
   "source": [
    "email_df = pd.DataFrame(parse_into_emails(enrondata.message))\n",
    "print(email_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Perspective score: toxiciy only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      Here is our forecast\n",
       "1         Traveling to have a business meeting takes the...\n",
       "2                            test successful.  way to go!!!\n",
       "3         Randy,Can you send me a schedule of the salary...\n",
       "4                                                          \n",
       "5         Greg,How about either next Tuesday or Thursday...\n",
       "6         Phillip Allen (pallen@enron.com)Mike Grigsby (...\n",
       "7                                                          \n",
       "8         I don't think these are required by the ISP2. ...\n",
       "9         ---------------------- Forwarded by Phillip K ...\n",
       "10        Mr. Buckner,For delivered gas behind San Diego...\n",
       "11        Lucy,Open them and save in the rentroll folder...\n",
       "12        ---------------------- Forwarded by Phillip K ...\n",
       "13        ---------------------- Forwarded by Phillip K ...\n",
       "14        Dave,Here are the names of the west desk membe...\n",
       "15                          Paula,35 million is finePhillip\n",
       "16        ---------------------- Forwarded by Phillip K ...\n",
       "17        Tim,mike grigsby is having problems with acces...\n",
       "18        ---------------------- Forwarded by Phillip K ...\n",
       "19        ---------------------- Forwarded by Phillip K ...\n",
       "20        Brenda,Please use the second check as the Octo...\n",
       "21        I think Fletch has a good CPA.  I am still doi...\n",
       "22        Brenda,Please use the second check as my Octob...\n",
       "23        ---------------------- Forwarded by Phillip K ...\n",
       "24        Liane,As we discussed yesterday, I am concerne...\n",
       "25        ---------------------- Forwarded by Phillip K ...\n",
       "26        ---------------------- Forwarded by Phillip K ...\n",
       "27        ---------------------- Forwarded by Phillip K ...\n",
       "28        Reagan,Just wanted to give you an update.  I h...\n",
       "29        Nymex expiration is during this time frame.  P...\n",
       "                                ...                        \n",
       "517371    a) I am not completely at liberty to touch all...\n",
       "517372    I am interested in a program for myself.  I am...\n",
       "517373    yes-----Original Message-----This is the first...\n",
       "517374    Its OKJohn Zufferli-----Original Message-----M...\n",
       "517375    you can increase the direct sale to include De...\n",
       "517376    You should talk to Jess about that, she is due...\n",
       "517377    -----Original Message-----John, I understand y...\n",
       "517378    Here is the update list that you requested. Mi...\n",
       "517379    i am waiting on the conference call and no one...\n",
       "517380    -----Original Message-----hey there.  dad told...\n",
       "517381    -----Original Message-----Everything from Ops,...\n",
       "517382    nothing new here, when is your flight? have yo...\n",
       "517383    In addition to a list of software and systems ...\n",
       "517384    Please set up access for the digital certifica...\n",
       "517385    Dece\\tmber 11, 2001-----Original Message----->...\n",
       "517386    -----Original Message-----going great.  Even t...\n",
       "517387    -----Original Message-----John, please check w...\n",
       "517388    Here is the info for the commercial staffJohn ...\n",
       "517389    Enron is willing to perform the operation unde...\n",
       "517390    CAND-MGMT-BAS for all AECO and DAWN BASISCAND-...\n",
       "517391                           -----Original Message-----\n",
       "517392    eric.le@enron.com, grant.oh@enron.com, dean.dr...\n",
       "517393    not yet, rob has been in the court house all d...\n",
       "517394    -----Original Message-----Good to hear your vo...\n",
       "517395    very busy, jess is ok just scared-----Original...\n",
       "517396    This is a trade with OIL-SPEC-HEDGE-NG (John L...\n",
       "517397    Some of my position is with the Alberta Term b...\n",
       "517398    2-----Original Message-----Morning John,I'm st...\n",
       "517399    Analyst\\t\\t\\t\\t\\tRankStephane Brodeur\\t\\t\\t1Ch...\n",
       "517400    i think the YMCA has a class that is for peopl...\n",
       "Name: body, Length: 517401, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_df.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # obtained from https://www.kaggle.com/tarunpaparaju/jigsaw-competition-google-perspective-api\n",
    "# # allowed test types\n",
    "# allowed = [\"TOXICITY\",\n",
    "#            \"SEVERE_TOXICITY\",\n",
    "#            \"TOXICITY_FAST\",\n",
    "#            \"ATTACK_ON_AUTHOR\",\n",
    "#            \"ATTACK_ON_COMMENTER\",\n",
    "#            \"INCOHERENT\",\n",
    "#            \"INFLAMMATORY\",\n",
    "#            \"OBSCENE\",\n",
    "#            \"OFF_TOPIC\",\n",
    "#            \"UNSUBSTANTIAL\",\n",
    "#            \"LIKELY_TO_REJECT\"]\n",
    "\n",
    "# class Perspective(object):\n",
    "\n",
    "#     base_url = \"https://commentanalyzer.googleapis.com/v1alpha1\"\n",
    "\n",
    "#     def __init__(self, key):\n",
    "#         self.key = key\n",
    "\n",
    "#     def score(self, text, tests=[\"TOXICITY\"], context=None, languages=None, do_not_store=False, token=None, text_type=None):\n",
    "#         # data validation\n",
    "#         # make sure it's a valid test\n",
    "#         # TODO: see if an endpoint that has valid types exists\n",
    "#         if isinstance(tests, str):\n",
    "#             tests = [tests]\n",
    "#         if not isinstance(tests, (list, dict)) or tests is None:\n",
    "#             raise ValueError(\"Invalid list/dictionary provided for tests\")\n",
    "#         if isinstance(tests, list):\n",
    "#             new_data = {}\n",
    "#             for test in tests:\n",
    "#                 new_data[test] = {}\n",
    "#             tests = new_data\n",
    "#         if text_type:\n",
    "#             if text_type.lower() == \"html\":\n",
    "#                 text = remove_html(text)\n",
    "#             elif text_type.lower() == \"md\":\n",
    "#                 text = remove_html(text, md=True)\n",
    "#             else:\n",
    "#                 raise ValueError(\"{0} is not a valid text_type. Valid options are 'html' or 'md'\".format(str(text_type)))\n",
    "\n",
    "#         for test in tests.keys():\n",
    "#             if test not in allowed:\n",
    "#                 warnings.warn(\"{0} might not be accepted as a valid test.\".format(str(test)))\n",
    "#             for key in tests[test].keys():\n",
    "#                 if key not in [\"scoreType\", \"scoreThreshhold\"]:\n",
    "#                     raise ValueError(\"{0} is not a valid sub-property for {1}\".format(key, test))\n",
    "\n",
    "#         # The API will only grade text less than 3k characters long\n",
    "#         if len(text) > 3000:\n",
    "#             # TODO: allow disassembly/reassembly of >3000char comments\n",
    "#             warnings.warn(\"Perspective only allows 3000 character strings. Only the first 3000 characters will be sent for processing\")\n",
    "#             text = text[:3000]\n",
    "#         new_langs = []\n",
    "#         if languages:\n",
    "#             for language in languages:\n",
    "#                 language = language.lower()\n",
    "#                 if validate_language(language):\n",
    "#                     new_langs.append(language)\n",
    "\n",
    "#         # packaging data\n",
    "#         url = Perspective.base_url + \"/comments:analyze\"\n",
    "#         querystring = {\"key\": self.key}\n",
    "#         payload_data = {\"comment\": {\"text\": text}, \"requestedAttributes\": {}}\n",
    "#         for test in tests.keys():\n",
    "#             payload_data[\"requestedAttributes\"][test] = tests[test]\n",
    "#         if new_langs != None:\n",
    "#             payload_data[\"languages\"] = new_langs\n",
    "#         if do_not_store:\n",
    "#             payload_data[\"doNotStore\"] = do_not_store\n",
    "#         payload = json.dumps(payload_data)\n",
    "#         headers = {'content-type': \"application/json\"}\n",
    "#         response = requests.post(url,\n",
    "#                             data=payload,\n",
    "#                             headers=headers,\n",
    "#                             params=querystring)\n",
    "#         data = response.json()\n",
    "#         if \"error\" in data.keys():\n",
    "#             raise PerspectiveAPIException(data[\"error\"][\"message\"])\n",
    "#         c = Comment(text, [], token)\n",
    "#         base = data[\"attributeScores\"]\n",
    "#         for test in tests.keys():\n",
    "#             score = base[test][\"summaryScore\"][\"value\"]\n",
    "#             score_type = base[test][\"summaryScore\"][\"type\"]\n",
    "#             a = Attribute(test, [], score, score_type)\n",
    "#             for span in base[test][\"spanScores\"]:\n",
    "#                 beginning = span[\"begin\"]\n",
    "#                 end = span[\"end\"]\n",
    "#                 score = span[\"score\"][\"value\"]\n",
    "#                 score_type = span[\"score\"][\"type\"]\n",
    "#                 s = Span(beginning, end, score, score_type, c)\n",
    "#                 a.spans.append(s)\n",
    "#             c.attributes.append(a)\n",
    "#         return c\n",
    "\n",
    "# class Comment(object):\n",
    "#     def __init__(self, text, attributes, token):\n",
    "#         self.text = text\n",
    "#         self.attributes = attributes\n",
    "#         self.token = token\n",
    "\n",
    "#     def __getitem__(self, key):\n",
    "#         if key.upper() not in allowed:\n",
    "#             raise ValueError(\"value {0} does not exist\".format(key))\n",
    "#         for attr in self.attributes:\n",
    "#             if attr.name.lower() == key.lower():\n",
    "#                 return attr\n",
    "#         raise ValueError(\"value {0} not found\".format(key))\n",
    "\n",
    "#     def __str__(self):\n",
    "#         return self.text\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         count = 0\n",
    "#         num = 0\n",
    "#         for attr in self.attributes:\n",
    "#             count += attr.score\n",
    "#             num += 1\n",
    "#         return \"<({0}) {1}>\".format(str(count/num), self.text)\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         return iter(self.attributes)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.text)\n",
    "\n",
    "# class Attribute(object):\n",
    "#     def __init__(self, name, spans, score, score_type):\n",
    "#         self.name = name\n",
    "#         self.spans = spans\n",
    "#         self.score = score\n",
    "#         self.score_type = score_type\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return self.spans[index]\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         return iter(self.spans)\n",
    "\n",
    "# class Span(object):\n",
    "#     def __init__(self, begin, end, score, score_type, comment):\n",
    "#         self.begin = begin\n",
    "#         self.end = end\n",
    "#         self.score = score\n",
    "#         self.score_type = score_type\n",
    "#         self.comment = comment\n",
    "\n",
    "#     def __str__(self):\n",
    "#         return self.comment.text[self.begin:self.end]\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         return \"<({0}) {1}>\".format(self.score, self.comment.text[self.begin:self.end])\n",
    "\n",
    "# class PerspectiveAPIException(Exception):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# client = Perspective(PerspectiveAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# emails = email_df['body']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 Here is our forecast\n",
       "1    Traveling to have a business meeting takes the...\n",
       "2                       test successful.  way to go!!!\n",
       "3    Randy,Can you send me a schedule of the salary...\n",
       "4                                                     \n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emails[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         EXAMPLE WORKING OF PERSPECTIVE API                          \n",
      "                         ----------------------------------                          \n",
      "\n",
      "email :\n",
      "Here is our forecast\n",
      "\n",
      "TOXICITY SCORE : 0.01873601\n",
      "--------------------------------------------------------------------------------------------\n",
      "\n",
      "email :\n",
      "Traveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.As far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.My suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\n",
      "\n",
      "TOXICITY SCORE : 0.0713822\n",
      "--------------------------------------------------------------------------------------------\n",
      "\n",
      "email :\n",
      "test successful.  way to go!!!\n",
      "\n",
      "TOXICITY SCORE : 0.07080242\n",
      "--------------------------------------------------------------------------------------------\n",
      "\n",
      "email :\n",
      "Randy,Can you send me a schedule of the salary and level of everyone in thescheduling group.  Plus your thoughts on any changes that need to be made.(Patti S for example)Phillip\n",
      "\n",
      "TOXICITY SCORE : 0.079820596\n",
      "--------------------------------------------------------------------------------------------\n",
      "\n",
      "email :\n",
      "Greg,How about either next Tuesday or Thursday?Phillip\n",
      "\n",
      "TOXICITY SCORE : 0.07649265\n",
      "--------------------------------------------------------------------------------------------\n",
      "\n",
      "email :\n",
      "Phillip Allen (pallen@enron.com)Mike Grigsby (mike.grigsby@enron.com)Keith Holst (kholst@enron.com)Monique SanchezFrank ErmisJohn LavoratoThank you for your helpPhillip Allen\n",
      "\n",
      "TOXICITY SCORE : 0.39299166\n",
      "--------------------------------------------------------------------------------------------\n",
      "\n",
      "email :\n",
      "I don't think these are required by the ISP2.  static IP address\n",
      "\n",
      "TOXICITY SCORE : 0.11937987\n",
      "--------------------------------------------------------------------------------------------\n",
      "\n",
      "email :\n",
      "---------------------- Forwarded by Phillip K Allen/HOU/ECT on 10/16/2000Phillip,> As discussed  during our phone conversation, In a Parallon 75 microturbine> power generation deal for a national accounts customer, I am developing a> proposal to sell power to customer at fixed or collar/floor price. To do> so I need a corresponding term gas price for same. Microturbine is an> onsite generation product developed by Honeywell to generate electricity> on customer site (degen). using natural gas. In doing so,  I need your> best fixed price forward gas price deal for 1, 3, 5, 7 and 10 years for> annual/seasonal supply to microturbines to generate fixed kWh for> customer. We have the opportunity to sell customer kWh 's using> microturbine or sell them turbines themselves. kWh deal must have limited/> no risk forward gas price to make deal work. Therein comes Sempra energy> gas trading, truly you.>> We are proposing installing 180 - 240 units across a large number of> stores (60-100) in San Diego.> Store number varies because of installation hurdles face at small percent.>> Gas requirement for 180 microturbines 227 - 302 MMcf per year> Gas requirement for 240 microturbines 302 - 403 MMcf per year>> Gas will likely be consumed from May through September, during peak> electric period.> Need detail breakout of commodity and transport cost (firm or> interruptible).>> Should you have additional questions, give me a call.> Let me assure you, this is real deal!!>> Buck Buckner, P.E., MBA> Manager, Business Development and Planning> Big Box Retail Sales> Honeywell Power Systems, Inc.> 8725 Pan American Frwy> Albuquerque, NM 87113> 505-798-6424> 505-798-6050x> 505-220-4129> 888/501-3145>\n",
      "\n",
      "TOXICITY SCORE : 0.09191043\n",
      "--------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# toxicity_scores = []\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "# print(\"                         EXAMPLE WORKING OF PERSPECTIVE API                          \")\n",
    "# print(\"                         ----------------------------------                          \")\n",
    "# print(\"\")\n",
    "# for i, email in enumerate(emails[:10]):\n",
    "#     if email == '':\n",
    "#         continue\n",
    "\n",
    "#     current = time.time()\n",
    "#     time.sleep((i + 1) - (current - start)) # limit API calls to 1 per second\n",
    "#     toxicity = client.score(email, tests=[\"TOXICITY\"])\n",
    "\n",
    "#     toxicity_scores.append(toxicity[\"TOXICITY\"].score)\n",
    "\n",
    "#     if i <= 50:\n",
    "#         print(\"email :\\n\" + email)\n",
    "#         print(\"\")\n",
    "#         print(\"TOXICITY SCORE : \" + str(toxicity[\"TOXICITY\"].score) )\n",
    "\n",
    "#         print((\"*********************************************************************\"+\\\n",
    "#                \"***********************\").replace('*', '-'))\n",
    "#         print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add score to all emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_perspective_score(email_list):\n",
    "#     start = time.time()\n",
    "#     toxicity_scores = []\n",
    "    \n",
    "#     for i, email in enumerate(email_list):\n",
    "        \n",
    "#         if email == '' or not re.search('[a-zA-Z]+', email) or  detect(email) != 'en' :\n",
    "#             # Perspective only works with english. Remove empty strings and non English emails\n",
    "#             toxicity_scores.append(0)\n",
    "#         else:\n",
    "\n",
    "#             current = time.time()\n",
    "#             time.sleep((i + 1) - (current - start)) # limit API calls to 1 per second\n",
    "#             toxicity = client.score(email, tests=[\"TOXICITY\"])\n",
    "\n",
    "#             toxicity_scores.append(toxicity[\"TOXICITY\"].score)\n",
    "#         print(i)\n",
    "            \n",
    "\n",
    "#     return toxicity_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# print (re.search('[a-zA-Z]+','2000-1969=31'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194    Are there behind closed doors discussions bein...\n",
       "195                                         2000-1969=31\n",
       "196    Mary,I spoke to Gary about the foundation work...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emails[194:197]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, email in enumerate(emails):\n",
    "#     print(i)\n",
    "#     if email != '':\n",
    "#         detect(email) != 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# toxicity_scores_all = get_perspective_score(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## total count\n",
    "## 517398"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(email_df.iloc[13,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(enrondata.iloc[13,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# email_df.body.iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at length of email, and how many are forwarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_pattern = 'Smug, paranoid, unhappy mother fucker.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got this from late friday. have you ever heard of him ?-----Original Message-----Fuck you, you piece of shit.  I can't wait to see yougo down with the ship like all the other vermin.Smug, paranoid, unhappy mother fucker.Eat shit.__________________________________________________Do You Yahoo!?Yahoo! GeoCities - quick and easy web site hosting, just $8.95/month.\n",
      "5602\n",
      "Fuck you, you piece of shit.  I can't wait to see yougo down with the ship like all the other vermin.Smug, paranoid, unhappy mother fucker.Eat shit.__________________________________________________Do You Yahoo!?Yahoo! GeoCities - quick and easy web site hosting, just $8.95/month.\n",
      "516229\n",
      "no.What city/country do you think Skilling's going to move to?-----Original Message-----got this from late friday. have you ever heard of him ?-----Original Message-----Fuck you, you piece of shit.  I can't wait to see yougo down with the ship like all the other vermin.Smug, paranoid, unhappy mother fucker.Eat shit.__________________________________________________Do You Yahoo!?Yahoo! GeoCities - quick and easy web site hosting, just $8.95/month.\n",
      "516231\n",
      "Robert, Here are the two messages from \"Jeff Lawson\" and the response I got from Jeff Sprecher at the ICE regarding my complaint. I appreciate your handling this matter.Andy--------- Inline attachment follows ---------HA HA HA YOU STUPID, ARROGANT FUCK__________________________________________________Do You Yahoo!?Buy the perfect holiday gifts at Yahoo! Shopping.--------- Inline attachment follows ---------Fuck you, you piece of shit.  I can't wait to see yougo down with the ship like all the other vermin.Smug, paranoid, unhappy mother fucker.Eat shit.__________________________________________________Do You Yahoo!?Yahoo! GeoCities - quick and easy web site hosting, just $8.95/month.--------- Inline attachment follows ---------Andy,We pulled the log ... found the guy ... and told him to knock it off.Please let me know if there is a repeat performance.Best regards, Jeff\n",
      "516592\n",
      "got this from late friday. have you ever heard of him ?-----Original Message-----Fuck you, you piece of shit.  I can't wait to see yougo down with the ship like all the other vermin.Smug, paranoid, unhappy mother fucker.Eat shit.__________________________________________________Do You Yahoo!?Yahoo! GeoCities - quick and easy web site hosting, just $8.95/month.\n",
      "516660\n"
     ]
    }
   ],
   "source": [
    "for ind, email in enumerate (email_body):\n",
    "    if toxic_pattern in email:\n",
    "        print(email)\n",
    "        print(ind)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In other words, the forwarded messages very likely will also appear in the data\n",
    "So we can't split the forwarded emails into new emails, will create duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_forward = email_body.map(lambda x: len(x.split(\"---------------------- Forwarded by \"))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = email_body.map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           20\n",
       "1          779\n",
       "2           30\n",
       "3          177\n",
       "4            0\n",
       "5           54\n",
       "6          174\n",
       "7            0\n",
       "8           64\n",
       "9         1700\n",
       "10         201\n",
       "11         163\n",
       "12        4716\n",
       "13        4716\n",
       "14         105\n",
       "15          31\n",
       "16         440\n",
       "17         141\n",
       "18        1470\n",
       "19         315\n",
       "20         135\n",
       "21          56\n",
       "22         137\n",
       "23        2089\n",
       "24        2032\n",
       "25        8189\n",
       "26        8189\n",
       "27        3157\n",
       "28         461\n",
       "29          63\n",
       "          ... \n",
       "517371    2504\n",
       "517372     383\n",
       "517373     136\n",
       "517374    2436\n",
       "517375      78\n",
       "517376     498\n",
       "517377     592\n",
       "517378     288\n",
       "517379    1071\n",
       "517380     807\n",
       "517381     409\n",
       "517382     795\n",
       "517383    1923\n",
       "517384     170\n",
       "517385    1163\n",
       "517386    1480\n",
       "517387      91\n",
       "517388     138\n",
       "517389    2696\n",
       "517390    1272\n",
       "517391      26\n",
       "517392     377\n",
       "517393      98\n",
       "517394     380\n",
       "517395     575\n",
       "517396     329\n",
       "517397     116\n",
       "517398     214\n",
       "517399     157\n",
       "517400    2952\n",
       "Name: body, Length: 517401, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 32), match='---------------------- Forwarded'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re.search(forward_pattern, test_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here is our forecast']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_body[0].split(\"---------------------- Forwarded by \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"---------------------- Forwarded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " \"Phillip K Allen/HOU/ECT on 10/09/2000Richard BurchfieldPhillip,Below is the issues & to do list as we go forward with documenting therequirements for consolidated physical/financial positions and transporttrade capture. What we need to focus on is the first bullet in Allan's list;the need for a single set of requirements. Although the meeting with Keith,on Wednesday,  was informative the solution of creating a infinitely dynamicconsolidated position screen, will be extremely difficult and timeconsuming.  Throughout the meeting on Wednesday, Keith alluded to theinability to get consensus amongst the traders on the presentation of theconsolidated position, so the solution was to make it so that a trader canarrange the position screen to their liking (much like Excel). What needs tohappen on Monday from 3 - 5 is a effort to design a desired layout for theconsolidated position screen, this is critical. This does not excludebuilding a capability to create a more flexible position presentation for thefuture, but in order to create a plan that can be measured we need firmrequirements. Also, to reiterate that the goals of this project is a projectplan on consolidate physical/financial positions and transport trade capture.The other issues that have been raised will be capture as projects on tothemselves, and will need to be prioritised as efforts outside of thisproject.I have been involved in most of the meetings and the discussions have beengood. I believe there has been good communication between the teams, but nowwe need to have focus on the objectives we set out to solve.Richard\",\n",
       " \"Richard Burchfield/HOU/ECT on 10/06/2000Allan SeverudeMills/HOU/ECT@ECT, Kenny Ha/HOU/ECT@ECTFrom our initial set of meetings with the traders regarding consolidatedWe don't have a single point of contact from the trading group.  We've hadthree meetings which brought out very different issues from differenttraders.  We really need a single point of contact to help drive the traderrequirements and help come to a consensus regarding the requirements.We're getting hit with a lot of different requests, many of which appear tobe outside the scope of position consolidation.I think it may be useful to try to formulate a high level project goal tomake it as clear as possible what we're trying to accomplish with thisproject.  It'll help determine which requests fall under the project scope.Go through the list of requests to determine which are in scope for thisproject and which fall out of scope.For those in scope, work to define relative importance (priority) of each andwork with traders to define the exact requirements of each.drill downs.Use the above to formulate a project plan.Inclusion of Sitara physical deals into the TDS position manager and dealticker.Customized rows and columns in the position manager (ad hoc rows/columns thatadd up existing position manager rows/columns).transport, swaps, options, ...Addition of a curve tab to the position manager to show the real-time valuesof all curves on which the desk has a position.Ability to split the current position grid to allow daily positions to beshown directly above monthly positions.  Each grouped column in the top gridwould be tied to a grouped column in the bottom grid.Ability to properly show curve shift for float-for-float deals; determine theGas Daily for monthly index,Physical gas for Nymex,Physical gas for Inside Ferc,Physical gas for Mid market.Ability for TDS to pull valuation results based on a TDS flag instead ofusing official valuations.Position and P&L aggregation across all gas desks.Inclusion of spread options in our systems.  Ability to handle volatilityskew and correlations.Ability to revalue all options incrementally throughout the trading day.Approximate delta changes between valuations using instantaneous gamma or agamma grid.Valuation of Gas Daily options.A new position screen for options (months x strike x delta).  TBD.Inclusion of positions for exotic options currently managed in spreadsheets.Ability to isolate the position change due to changed deals in the positionmanager.Ability to view change deal P&L in the TDS deal ticker.  Show new deal terms,prior deal terms, and net P&L affect of the change.Eliminate change deals with no economic impact from the TDS deal ticker.Position drill down in the position manager to isolate the impact ofindividual deals on the position total in a grid cell.Benchmark positions in TDS.Deployment of TDS in Canada. Currency and volume uom conversions. Implicitand explicit position break out issues.-- Allan.transport.  Hopefully we'll know much better where that part stands at thatpoint.\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_email.split(\"---------------------- Forwarded by \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (re.search('[a-zA-Z]+','2000-1969=31'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  Here is our forecast\n",
       "1     Traveling to have a business meeting takes the...\n",
       "2                        test successful.  way to go!!!\n",
       "3     Randy,Can you send me a schedule of the salary...\n",
       "4                                                      \n",
       "5     Greg,How about either next Tuesday or Thursday...\n",
       "6     Phillip Allen (pallen@enron.com)Mike Grigsby (...\n",
       "7                                                      \n",
       "8     I don't think these are required by the ISP2. ...\n",
       "9     ---------------------- Forwarded by Phillip K ...\n",
       "10    Mr. Buckner,For delivered gas behind San Diego...\n",
       "11    Lucy,Open them and save in the rentroll folder...\n",
       "12    ---------------------- Forwarded by Phillip K ...\n",
       "13    ---------------------- Forwarded by Phillip K ...\n",
       "14    Dave,Here are the names of the west desk membe...\n",
       "15                      Paula,35 million is finePhillip\n",
       "16    ---------------------- Forwarded by Phillip K ...\n",
       "17    Tim,mike grigsby is having problems with acces...\n",
       "18    ---------------------- Forwarded by Phillip K ...\n",
       "19    ---------------------- Forwarded by Phillip K ...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_body = email_df.body\n",
    "email_body[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"---------------------- Forwarded by Phillip K Allen/HOU/ECT on 10/09/2000Richard BurchfieldPhillip,Below is the issues & to do list as we go forward with documenting therequirements for consolidated physical/financial positions and transporttrade capture. What we need to focus on is the first bullet in Allan's list;the need for a single set of requirements. Although the meeting with Keith,on Wednesday,  was informative the solution of creating a infinitely dynamicconsolidated position screen, will be extremely difficult and timeconsuming.  Throughout the meeting on Wednesday, Keith alluded to theinability to get consensus amongst the traders on the presentation of theconsolidated position, so the solution was to make it so that a trader canarrange the position screen to their liking (much like Excel). What needs tohappen on Monday from 3 - 5 is a effort to design a desired layout for theconsolidated position screen, this is critical. This does not excludebuilding a capability to create a more flexible position presentation for thefuture, but in order to create a plan that can be measured we need firmrequirements. Also, to reiterate that the goals of this project is a projectplan on consolidate physical/financial positions and transport trade capture.The other issues that have been raised will be capture as projects on tothemselves, and will need to be prioritised as efforts outside of thisproject.I have been involved in most of the meetings and the discussions have beengood. I believe there has been good communication between the teams, but nowwe need to have focus on the objectives we set out to solve.Richard---------------------- Forwarded by Richard Burchfield/HOU/ECT on 10/06/2000Allan SeverudeMills/HOU/ECT@ECT, Kenny Ha/HOU/ECT@ECTFrom our initial set of meetings with the traders regarding consolidatedWe don't have a single point of contact from the trading group.  We've hadthree meetings which brought out very different issues from differenttraders.  We really need a single point of contact to help drive the traderrequirements and help come to a consensus regarding the requirements.We're getting hit with a lot of different requests, many of which appear tobe outside the scope of position consolidation.I think it may be useful to try to formulate a high level project goal tomake it as clear as possible what we're trying to accomplish with thisproject.  It'll help determine which requests fall under the project scope.Go through the list of requests to determine which are in scope for thisproject and which fall out of scope.For those in scope, work to define relative importance (priority) of each andwork with traders to define the exact requirements of each.drill downs.Use the above to formulate a project plan.Inclusion of Sitara physical deals into the TDS position manager and dealticker.Customized rows and columns in the position manager (ad hoc rows/columns thatadd up existing position manager rows/columns).transport, swaps, options, ...Addition of a curve tab to the position manager to show the real-time valuesof all curves on which the desk has a position.Ability to split the current position grid to allow daily positions to beshown directly above monthly positions.  Each grouped column in the top gridwould be tied to a grouped column in the bottom grid.Ability to properly show curve shift for float-for-float deals; determine theGas Daily for monthly index,Physical gas for Nymex,Physical gas for Inside Ferc,Physical gas for Mid market.Ability for TDS to pull valuation results based on a TDS flag instead ofusing official valuations.Position and P&L aggregation across all gas desks.Inclusion of spread options in our systems.  Ability to handle volatilityskew and correlations.Ability to revalue all options incrementally throughout the trading day.Approximate delta changes between valuations using instantaneous gamma or agamma grid.Valuation of Gas Daily options.A new position screen for options (months x strike x delta).  TBD.Inclusion of positions for exotic options currently managed in spreadsheets.Ability to isolate the position change due to changed deals in the positionmanager.Ability to view change deal P&L in the TDS deal ticker.  Show new deal terms,prior deal terms, and net P&L affect of the change.Eliminate change deals with no economic impact from the TDS deal ticker.Position drill down in the position manager to isolate the impact ofindividual deals on the position total in a grid cell.Benchmark positions in TDS.Deployment of TDS in Canada. Currency and volume uom conversions. Implicitand explicit position break out issues.-- Allan.transport.  Hopefully we'll know much better where that part stands at thatpoint.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_email = email_body[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"---------------------- Forwarded by Phillip K Allen/HOU/ECT on 10/03/2000Please respond to <cbpres@austin.rr.com>WestgateEnclosed are demographics on the Westgate site from Investor's Alliance.Investor's Alliance says that these demographics are similar to the packageon San Marcos that you received earlier.If there are any other questions or information requirements, let me know.Then, let me know your interest level in the Westgate project?San MarcosThe property across the street from the Sagewood units in San Marcos is forsale and approved for 134 units.  The land is selling for $2.50 per squarefoot as it is one of only two remaining approved multifamily parcels in WestSan Marcos, which now has a moratorium on development.Several new studies we have looked at show that the rents for our duplexesand for these new units are going to be significantly higher, roughly $1.25per square foot if leased for the entire unit on a 12-month lease and$1.30-$1.40 psf if leased on a 12-month term, but by individual room.  Thisproperty will have the best location for student housing of all newprojects, just as the duplexes do now.If this project is of serious interest to you, please let me know as thereis a very, very short window of opportunity.  The equity requirement is notyet known, but it would be likely to be $300,000 to secure the land.  I willknow more on this question later today.Sincerely,George W. RichardsPresident, Creekside Builders, LLC- winmail.dat\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_body[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes-----Original Message-----This is the first that I have heard of this.  Something for Mike to look at ?Mark-----Original Message-----'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_body[517373]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
