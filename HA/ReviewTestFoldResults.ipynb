{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.evaluate import load_dev_labels, get_metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 373580.30it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:13, 76.35s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold0.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold0.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  331\n",
      "False Positives per class :  199\n",
      "False Negatives per class :  78\n",
      "Accuracy : 0.8153, Precision : 0.625, Recall : 0.809, F1 : 0.705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8153333333333334,\n",
       " 0.6245283018867924,\n",
       " 0.8092909535452323,\n",
       " 0.7050053248136317)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test0 = pd.read_csv(\"/data/SuperMod/testfolds/fold0.csv\")\n",
    "with open('/data/SuperMod/infer_result_fold0.pkl', 'rb') as w:\n",
    "    result0 = pkl.load(w)\n",
    "get_metrics(np.asarray(test0.toxicity), np.asarray(result0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 370034.50it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:13, 76.12s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold1.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold1.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  356\n",
      "False Positives per class :  225\n",
      "False Negatives per class :  66\n",
      "Accuracy : 0.8060, Precision : 0.613, Recall : 0.844, F1 : 0.710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.806, 0.612736660929432, 0.8436018957345972, 0.7098703888334996)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = pd.read_csv(\"/data/SuperMod/testfolds/fold1.csv\")\n",
    "with open('/data/SuperMod/infer_result_fold1.pkl', 'rb') as w:\n",
    "    result1 = pkl.load(w)\n",
    "get_metrics(np.asarray(test1.toxicity), np.asarray(result1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 368757.78it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:10, 75.82s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold2.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold2.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  328\n",
      "False Positives per class :  221\n",
      "False Negatives per class :  81\n",
      "Accuracy : 0.7987, Precision : 0.597, Recall : 0.802, F1 : 0.685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7986666666666666,\n",
       " 0.5974499089253188,\n",
       " 0.8019559902200489,\n",
       " 0.6847599164926931)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = pd.read_csv(\"/data/SuperMod/testfolds/fold2.csv\")\n",
    "with open('/data/SuperMod/infer_result_fold2.pkl', 'rb') as w:\n",
    "    result2 = pkl.load(w)\n",
    "get_metrics(np.asarray(test2.toxicity), np.asarray(result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 374268.57it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:07, 75.51s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold3.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold3.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 374668.03it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:08, 75.75s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold4.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold4.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 375580.45it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:13, 76.39s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold5.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold5.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 374873.94it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:07, 75.56s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold6.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold6.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 371721.52it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:15, 76.52s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold7.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold7.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 373390.76it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:07, 75.90s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold8.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold8.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 373958.28it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:09, 75.83s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold9.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold9.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 373848.31it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:07, 75.67s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold10.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold10.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 373086.90it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:10, 75.97s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold11.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold11.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 371752.82it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:07, 75.68s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold12.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold12.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 370927.74it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:09, 75.70s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold13.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold13.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 377758.55it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:10, 75.97s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold14.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold14.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 379413.92it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:10, 75.88s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold15.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold15.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 366598.63it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:10, 75.38s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold16.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold16.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 376524.36it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:10, 75.99s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold17.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold17.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 372599.77it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:09, 75.81s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold18.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold18.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 371934.10it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:08, 75.65s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold19.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold19.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 370613.15it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:10, 76.04s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold20.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold20.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 363635.30it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:07, 75.59s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold21.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold21.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 376610.55it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:07, 75.51s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold22.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold22.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 378462.32it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:09, 76.13s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold23.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold23.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 379300.71it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:08, 75.76s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold24.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold24.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 371329.96it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:07, 75.73s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold25.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold25.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 372955.88it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:14, 76.56s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold26.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold26.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 367404.54it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:12, 76.10s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold27.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold27.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 347913.58it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:12, 76.17s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold28.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold28.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 379508.32it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:10, 75.90s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold29.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold29.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 373883.29it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:10, 75.97s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold30.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold30.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 379451.68it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:11, 76.21s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold31.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold31.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 378692.94it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:12, 75.79s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold32.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold32.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 373485.50it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:10, 75.83s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold33.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold33.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 369067.61it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:08, 75.78s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold34.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold34.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 372288.94it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:15, 76.05s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold35.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold35.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 375435.91it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:09, 75.79s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold36.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold36.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 372414.53it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:12, 75.98s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold37.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold37.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 373387.43it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:10, 75.76s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold38.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold38.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 371182.11it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:12, 76.15s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold39.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold39.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 377540.96it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:08, 75.71s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold40.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold40.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 374397.17it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:08, 75.68s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold41.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold41.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 377843.61it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:13, 76.38s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold42.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold42.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 374143.39it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:09, 75.65s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold43.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold43.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 364459.87it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:13, 76.59s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold44.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold44.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 377389.82it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:10, 75.55s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold45.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold45.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 375789.05it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:12, 76.05s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold46.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold46.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 374666.36it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:09, 75.72s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold47.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold47.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 374464.02it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:10, 75.84s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold48.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold48.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "Tokenizing using dictionary from /data/torchMoji/model/vocabulary.json\n",
      "loading pkl file\n",
      "loading finished\n",
      "loading glove\n",
      "100%|█████████████████████████████████| 20003/20003 [00:00<00:00, 374188.45it/s]\n",
      "15614 of 20003 found coverage 0.7805829125631155\n",
      "8it [10:12, 76.01s/it]                                                          \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python inference_ha.py -test_path \"/data/SuperMod/testfolds/fold49.csv\"  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "-infer_result '/data/SuperMod/infer_result_fold49.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting results for fold 0\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  364\n",
      "False Positives per class :  174\n",
      "False Negatives per class :  45\n",
      "Accuracy : 0.8540, Precision : 0.677, Recall : 0.890, F1 : 0.769\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  331\n",
      "False Positives per class :  199\n",
      "False Negatives per class :  78\n",
      "Accuracy : 0.8153, Precision : 0.625, Recall : 0.809, F1 : 0.705\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  381\n",
      "False Positives per class :  271\n",
      "False Negatives per class :  28\n",
      "Accuracy : 0.8007, Precision : 0.584, Recall : 0.932, F1 : 0.718\n",
      "\n",
      "getting results for fold 1\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  377\n",
      "False Positives per class :  172\n",
      "False Negatives per class :  45\n",
      "Accuracy : 0.8553, Precision : 0.687, Recall : 0.893, F1 : 0.777\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  356\n",
      "False Positives per class :  225\n",
      "False Negatives per class :  66\n",
      "Accuracy : 0.8060, Precision : 0.613, Recall : 0.844, F1 : 0.710\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  396\n",
      "False Positives per class :  281\n",
      "False Negatives per class :  26\n",
      "Accuracy : 0.7953, Precision : 0.585, Recall : 0.938, F1 : 0.721\n",
      "\n",
      "getting results for fold 2\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  360\n",
      "False Positives per class :  173\n",
      "False Negatives per class :  49\n",
      "Accuracy : 0.8520, Precision : 0.675, Recall : 0.880, F1 : 0.764\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  328\n",
      "False Positives per class :  221\n",
      "False Negatives per class :  81\n",
      "Accuracy : 0.7987, Precision : 0.597, Recall : 0.802, F1 : 0.685\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  388\n",
      "False Positives per class :  280\n",
      "False Negatives per class :  21\n",
      "Accuracy : 0.7993, Precision : 0.581, Recall : 0.949, F1 : 0.721\n",
      "\n",
      "getting results for fold 3\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  349\n",
      "False Positives per class :  184\n",
      "False Negatives per class :  50\n",
      "Accuracy : 0.8440, Precision : 0.655, Recall : 0.875, F1 : 0.749\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  310\n",
      "False Positives per class :  211\n",
      "False Negatives per class :  89\n",
      "Accuracy : 0.8000, Precision : 0.595, Recall : 0.777, F1 : 0.674\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  375\n",
      "False Positives per class :  288\n",
      "False Negatives per class :  24\n",
      "Accuracy : 0.7920, Precision : 0.566, Recall : 0.940, F1 : 0.706\n",
      "\n",
      "getting results for fold 4\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  382\n",
      "False Positives per class :  164\n",
      "False Negatives per class :  43\n",
      "Accuracy : 0.8620, Precision : 0.700, Recall : 0.899, F1 : 0.787\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  344\n",
      "False Positives per class :  214\n",
      "False Negatives per class :  81\n",
      "Accuracy : 0.8033, Precision : 0.616, Recall : 0.809, F1 : 0.700\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  401\n",
      "False Positives per class :  281\n",
      "False Negatives per class :  24\n",
      "Accuracy : 0.7967, Precision : 0.588, Recall : 0.944, F1 : 0.724\n",
      "\n",
      "getting results for fold 5\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  355\n",
      "False Positives per class :  158\n",
      "False Negatives per class :  45\n",
      "Accuracy : 0.8647, Precision : 0.692, Recall : 0.887, F1 : 0.778\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  327\n",
      "False Positives per class :  220\n",
      "False Negatives per class :  73\n",
      "Accuracy : 0.8047, Precision : 0.598, Recall : 0.818, F1 : 0.691\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  379\n",
      "False Positives per class :  276\n",
      "False Negatives per class :  21\n",
      "Accuracy : 0.8020, Precision : 0.579, Recall : 0.948, F1 : 0.718\n",
      "\n",
      "getting results for fold 6\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  351\n",
      "False Positives per class :  165\n",
      "False Negatives per class :  44\n",
      "Accuracy : 0.8607, Precision : 0.680, Recall : 0.889, F1 : 0.771\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  312\n",
      "False Positives per class :  217\n",
      "False Negatives per class :  83\n",
      "Accuracy : 0.8000, Precision : 0.590, Recall : 0.790, F1 : 0.675\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  369\n",
      "False Positives per class :  269\n",
      "False Negatives per class :  26\n",
      "Accuracy : 0.8033, Precision : 0.578, Recall : 0.934, F1 : 0.714\n",
      "\n",
      "getting results for fold 7\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  339\n",
      "False Positives per class :  158\n",
      "False Negatives per class :  40\n",
      "Accuracy : 0.8680, Precision : 0.682, Recall : 0.894, F1 : 0.774\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  304\n",
      "False Positives per class :  195\n",
      "False Negatives per class :  75\n",
      "Accuracy : 0.8200, Precision : 0.609, Recall : 0.802, F1 : 0.692\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  357\n",
      "False Positives per class :  252\n",
      "False Negatives per class :  22\n",
      "Accuracy : 0.8173, Precision : 0.586, Recall : 0.942, F1 : 0.723\n",
      "\n",
      "getting results for fold 8\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  345\n",
      "False Positives per class :  148\n",
      "False Negatives per class :  46\n",
      "Accuracy : 0.8707, Precision : 0.700, Recall : 0.882, F1 : 0.781\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  311\n",
      "False Positives per class :  193\n",
      "False Negatives per class :  80\n",
      "Accuracy : 0.8180, Precision : 0.617, Recall : 0.795, F1 : 0.695\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  368\n",
      "False Positives per class :  250\n",
      "False Negatives per class :  23\n",
      "Accuracy : 0.8180, Precision : 0.595, Recall : 0.941, F1 : 0.729\n",
      "\n",
      "getting results for fold 9\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  351\n",
      "False Positives per class :  132\n",
      "False Negatives per class :  52\n",
      "Accuracy : 0.8773, Precision : 0.727, Recall : 0.871, F1 : 0.792\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  320\n",
      "False Positives per class :  202\n",
      "False Negatives per class :  83\n",
      "Accuracy : 0.8100, Precision : 0.613, Recall : 0.794, F1 : 0.692\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  372\n",
      "False Positives per class :  250\n",
      "False Negatives per class :  31\n",
      "Accuracy : 0.8127, Precision : 0.598, Recall : 0.923, F1 : 0.726\n",
      "\n",
      "getting results for fold 10\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  355\n",
      "False Positives per class :  154\n",
      "False Negatives per class :  41\n",
      "Accuracy : 0.8700, Precision : 0.697, Recall : 0.896, F1 : 0.785\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  315\n",
      "False Positives per class :  218\n",
      "False Negatives per class :  81\n",
      "Accuracy : 0.8007, Precision : 0.591, Recall : 0.795, F1 : 0.678\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  376\n",
      "False Positives per class :  281\n",
      "False Negatives per class :  20\n",
      "Accuracy : 0.7993, Precision : 0.572, Recall : 0.949, F1 : 0.714\n",
      "\n",
      "getting results for fold 11\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  361\n",
      "False Positives per class :  187\n",
      "False Negatives per class :  40\n",
      "Accuracy : 0.8487, Precision : 0.659, Recall : 0.900, F1 : 0.761\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  322\n",
      "False Positives per class :  230\n",
      "False Negatives per class :  79\n",
      "Accuracy : 0.7940, Precision : 0.583, Recall : 0.803, F1 : 0.676\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  376\n",
      "False Positives per class :  295\n",
      "False Negatives per class :  25\n",
      "Accuracy : 0.7867, Precision : 0.560, Recall : 0.938, F1 : 0.701\n",
      "\n",
      "getting results for fold 12\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  354\n",
      "False Positives per class :  160\n",
      "False Negatives per class :  45\n",
      "Accuracy : 0.8633, Precision : 0.689, Recall : 0.887, F1 : 0.775\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  313\n",
      "False Positives per class :  231\n",
      "False Negatives per class :  86\n",
      "Accuracy : 0.7887, Precision : 0.575, Recall : 0.784, F1 : 0.664\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  374\n",
      "False Positives per class :  279\n",
      "False Negatives per class :  25\n",
      "Accuracy : 0.7973, Precision : 0.573, Recall : 0.937, F1 : 0.711\n",
      "\n",
      "getting results for fold 13\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  374\n",
      "False Positives per class :  166\n",
      "False Negatives per class :  50\n",
      "Accuracy : 0.8560, Precision : 0.693, Recall : 0.882, F1 : 0.776\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  350\n",
      "False Positives per class :  208\n",
      "False Negatives per class :  74\n",
      "Accuracy : 0.8120, Precision : 0.627, Recall : 0.825, F1 : 0.713\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  402\n",
      "False Positives per class :  268\n",
      "False Negatives per class :  22\n",
      "Accuracy : 0.8067, Precision : 0.600, Recall : 0.948, F1 : 0.735\n",
      "\n",
      "getting results for fold 14\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  348\n",
      "False Positives per class :  158\n",
      "False Negatives per class :  40\n",
      "Accuracy : 0.8680, Precision : 0.688, Recall : 0.897, F1 : 0.779\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  317\n",
      "False Positives per class :  226\n",
      "False Negatives per class :  71\n",
      "Accuracy : 0.8020, Precision : 0.584, Recall : 0.817, F1 : 0.681\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  370\n",
      "False Positives per class :  278\n",
      "False Negatives per class :  18\n",
      "Accuracy : 0.8027, Precision : 0.571, Recall : 0.954, F1 : 0.714\n",
      "\n",
      "getting results for fold 15\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  357\n",
      "False Positives per class :  161\n",
      "False Negatives per class :  50\n",
      "Accuracy : 0.8593, Precision : 0.689, Recall : 0.877, F1 : 0.772\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  343\n",
      "False Positives per class :  231\n",
      "False Negatives per class :  64\n",
      "Accuracy : 0.8033, Precision : 0.598, Recall : 0.843, F1 : 0.699\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  382\n",
      "False Positives per class :  283\n",
      "False Negatives per class :  25\n",
      "Accuracy : 0.7947, Precision : 0.574, Recall : 0.939, F1 : 0.713\n",
      "\n",
      "getting results for fold 16\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  376\n",
      "False Positives per class :  161\n",
      "False Negatives per class :  44\n",
      "Accuracy : 0.8633, Precision : 0.700, Recall : 0.895, F1 : 0.786\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  334\n",
      "False Positives per class :  218\n",
      "False Negatives per class :  86\n",
      "Accuracy : 0.7973, Precision : 0.605, Recall : 0.795, F1 : 0.687\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  398\n",
      "False Positives per class :  272\n",
      "False Negatives per class :  22\n",
      "Accuracy : 0.8040, Precision : 0.594, Recall : 0.948, F1 : 0.730\n",
      "\n",
      "getting results for fold 17\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  346\n",
      "False Positives per class :  160\n",
      "False Negatives per class :  40\n",
      "Accuracy : 0.8667, Precision : 0.684, Recall : 0.896, F1 : 0.776\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  296\n",
      "False Positives per class :  198\n",
      "False Negatives per class :  90\n",
      "Accuracy : 0.8080, Precision : 0.599, Recall : 0.767, F1 : 0.673\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  359\n",
      "False Positives per class :  263\n",
      "False Negatives per class :  27\n",
      "Accuracy : 0.8067, Precision : 0.577, Recall : 0.930, F1 : 0.712\n",
      "\n",
      "getting results for fold 18\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  367\n",
      "False Positives per class :  158\n",
      "False Negatives per class :  53\n",
      "Accuracy : 0.8593, Precision : 0.699, Recall : 0.874, F1 : 0.777\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  346\n",
      "False Positives per class :  215\n",
      "False Negatives per class :  74\n",
      "Accuracy : 0.8073, Precision : 0.617, Recall : 0.824, F1 : 0.705\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  392\n",
      "False Positives per class :  268\n",
      "False Negatives per class :  28\n",
      "Accuracy : 0.8027, Precision : 0.594, Recall : 0.933, F1 : 0.726\n",
      "\n",
      "getting results for fold 19\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  353\n",
      "False Positives per class :  172\n",
      "False Negatives per class :  49\n",
      "Accuracy : 0.8527, Precision : 0.672, Recall : 0.878, F1 : 0.762\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  345\n",
      "False Positives per class :  246\n",
      "False Negatives per class :  57\n",
      "Accuracy : 0.7980, Precision : 0.584, Recall : 0.858, F1 : 0.695\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  381\n",
      "False Positives per class :  294\n",
      "False Negatives per class :  21\n",
      "Accuracy : 0.7900, Precision : 0.564, Recall : 0.948, F1 : 0.708\n",
      "\n",
      "getting results for fold 20\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  340\n",
      "False Positives per class :  163\n",
      "False Negatives per class :  49\n",
      "Accuracy : 0.8587, Precision : 0.676, Recall : 0.874, F1 : 0.762\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  310\n",
      "False Positives per class :  233\n",
      "False Negatives per class :  79\n",
      "Accuracy : 0.7920, Precision : 0.571, Recall : 0.797, F1 : 0.665\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  359\n",
      "False Positives per class :  290\n",
      "False Negatives per class :  30\n",
      "Accuracy : 0.7867, Precision : 0.553, Recall : 0.923, F1 : 0.692\n",
      "\n",
      "getting results for fold 21\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  344\n",
      "False Positives per class :  163\n",
      "False Negatives per class :  42\n",
      "Accuracy : 0.8633, Precision : 0.679, Recall : 0.891, F1 : 0.770\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  312\n",
      "False Positives per class :  213\n",
      "False Negatives per class :  74\n",
      "Accuracy : 0.8087, Precision : 0.594, Recall : 0.808, F1 : 0.685\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  362\n",
      "False Positives per class :  272\n",
      "False Negatives per class :  24\n",
      "Accuracy : 0.8027, Precision : 0.571, Recall : 0.938, F1 : 0.710\n",
      "\n",
      "getting results for fold 22\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  345\n",
      "False Positives per class :  176\n",
      "False Negatives per class :  49\n",
      "Accuracy : 0.8500, Precision : 0.662, Recall : 0.876, F1 : 0.754\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  323\n",
      "False Positives per class :  223\n",
      "False Negatives per class :  71\n",
      "Accuracy : 0.8040, Precision : 0.592, Recall : 0.820, F1 : 0.687\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  369\n",
      "False Positives per class :  284\n",
      "False Negatives per class :  25\n",
      "Accuracy : 0.7940, Precision : 0.565, Recall : 0.937, F1 : 0.705\n",
      "\n",
      "getting results for fold 23\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  366\n",
      "False Positives per class :  146\n",
      "False Negatives per class :  38\n",
      "Accuracy : 0.8773, Precision : 0.715, Recall : 0.906, F1 : 0.799\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  327\n",
      "False Positives per class :  228\n",
      "False Negatives per class :  77\n",
      "Accuracy : 0.7967, Precision : 0.589, Recall : 0.809, F1 : 0.682\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  376\n",
      "False Positives per class :  271\n",
      "False Negatives per class :  28\n",
      "Accuracy : 0.8007, Precision : 0.581, Recall : 0.931, F1 : 0.716\n",
      "\n",
      "getting results for fold 24\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  353\n",
      "False Positives per class :  165\n",
      "False Negatives per class :  40\n",
      "Accuracy : 0.8633, Precision : 0.681, Recall : 0.898, F1 : 0.775\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  317\n",
      "False Positives per class :  222\n",
      "False Negatives per class :  76\n",
      "Accuracy : 0.8013, Precision : 0.588, Recall : 0.807, F1 : 0.680\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  369\n",
      "False Positives per class :  282\n",
      "False Negatives per class :  24\n",
      "Accuracy : 0.7960, Precision : 0.567, Recall : 0.939, F1 : 0.707\n",
      "\n",
      "getting results for fold 25\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  334\n",
      "False Positives per class :  152\n",
      "False Negatives per class :  48\n",
      "Accuracy : 0.8667, Precision : 0.687, Recall : 0.874, F1 : 0.770\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  310\n",
      "False Positives per class :  235\n",
      "False Negatives per class :  72\n",
      "Accuracy : 0.7953, Precision : 0.569, Recall : 0.812, F1 : 0.669\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  356\n",
      "False Positives per class :  286\n",
      "False Negatives per class :  26\n",
      "Accuracy : 0.7920, Precision : 0.555, Recall : 0.932, F1 : 0.695\n",
      "\n",
      "getting results for fold 26\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  363\n",
      "False Positives per class :  150\n",
      "False Negatives per class :  49\n",
      "Accuracy : 0.8673, Precision : 0.708, Recall : 0.881, F1 : 0.785\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  326\n",
      "False Positives per class :  224\n",
      "False Negatives per class :  86\n",
      "Accuracy : 0.7933, Precision : 0.593, Recall : 0.791, F1 : 0.678\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  384\n",
      "False Positives per class :  273\n",
      "False Negatives per class :  28\n",
      "Accuracy : 0.7993, Precision : 0.584, Recall : 0.932, F1 : 0.718\n",
      "\n",
      "getting results for fold 27\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  342\n",
      "False Positives per class :  161\n",
      "False Negatives per class :  46\n",
      "Accuracy : 0.8620, Precision : 0.680, Recall : 0.881, F1 : 0.768\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  309\n",
      "False Positives per class :  219\n",
      "False Negatives per class :  79\n",
      "Accuracy : 0.8013, Precision : 0.585, Recall : 0.796, F1 : 0.675\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  360\n",
      "False Positives per class :  267\n",
      "False Negatives per class :  28\n",
      "Accuracy : 0.8033, Precision : 0.574, Recall : 0.928, F1 : 0.709\n",
      "\n",
      "getting results for fold 28\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  337\n",
      "False Positives per class :  171\n",
      "False Negatives per class :  45\n",
      "Accuracy : 0.8560, Precision : 0.663, Recall : 0.882, F1 : 0.757\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  315\n",
      "False Positives per class :  248\n",
      "False Negatives per class :  67\n",
      "Accuracy : 0.7900, Precision : 0.560, Recall : 0.825, F1 : 0.667\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  358\n",
      "False Positives per class :  305\n",
      "False Negatives per class :  24\n",
      "Accuracy : 0.7807, Precision : 0.540, Recall : 0.937, F1 : 0.685\n",
      "\n",
      "getting results for fold 29\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  328\n",
      "False Positives per class :  167\n",
      "False Negatives per class :  45\n",
      "Accuracy : 0.8587, Precision : 0.663, Recall : 0.879, F1 : 0.756\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  295\n",
      "False Positives per class :  238\n",
      "False Negatives per class :  78\n",
      "Accuracy : 0.7893, Precision : 0.553, Recall : 0.791, F1 : 0.651\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  348\n",
      "False Positives per class :  293\n",
      "False Negatives per class :  25\n",
      "Accuracy : 0.7880, Precision : 0.543, Recall : 0.933, F1 : 0.686\n",
      "\n",
      "getting results for fold 30\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  380\n",
      "False Positives per class :  163\n",
      "False Negatives per class :  40\n",
      "Accuracy : 0.8647, Precision : 0.700, Recall : 0.905, F1 : 0.789\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  336\n",
      "False Positives per class :  214\n",
      "False Negatives per class :  84\n",
      "Accuracy : 0.8013, Precision : 0.611, Recall : 0.800, F1 : 0.693\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  397\n",
      "False Positives per class :  271\n",
      "False Negatives per class :  23\n",
      "Accuracy : 0.8040, Precision : 0.594, Recall : 0.945, F1 : 0.730\n",
      "\n",
      "getting results for fold 31\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  368\n",
      "False Positives per class :  132\n",
      "False Negatives per class :  42\n",
      "Accuracy : 0.8840, Precision : 0.736, Recall : 0.898, F1 : 0.809\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  333\n",
      "False Positives per class :  222\n",
      "False Negatives per class :  77\n",
      "Accuracy : 0.8007, Precision : 0.600, Recall : 0.812, F1 : 0.690\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  384\n",
      "False Positives per class :  256\n",
      "False Negatives per class :  26\n",
      "Accuracy : 0.8120, Precision : 0.600, Recall : 0.937, F1 : 0.731\n",
      "\n",
      "getting results for fold 32\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  370\n",
      "False Positives per class :  166\n",
      "False Negatives per class :  48\n",
      "Accuracy : 0.8573, Precision : 0.690, Recall : 0.885, F1 : 0.776\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  342\n",
      "False Positives per class :  201\n",
      "False Negatives per class :  76\n",
      "Accuracy : 0.8153, Precision : 0.630, Recall : 0.818, F1 : 0.712\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  392\n",
      "False Positives per class :  278\n",
      "False Negatives per class :  26\n",
      "Accuracy : 0.7973, Precision : 0.585, Recall : 0.938, F1 : 0.721\n",
      "\n",
      "getting results for fold 33\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  358\n",
      "False Positives per class :  136\n",
      "False Negatives per class :  45\n",
      "Accuracy : 0.8793, Precision : 0.725, Recall : 0.888, F1 : 0.798\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  325\n",
      "False Positives per class :  223\n",
      "False Negatives per class :  78\n",
      "Accuracy : 0.7993, Precision : 0.593, Recall : 0.806, F1 : 0.683\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  379\n",
      "False Positives per class :  268\n",
      "False Negatives per class :  24\n",
      "Accuracy : 0.8053, Precision : 0.586, Recall : 0.940, F1 : 0.722\n",
      "\n",
      "getting results for fold 34\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  368\n",
      "False Positives per class :  155\n",
      "False Negatives per class :  48\n",
      "Accuracy : 0.8647, Precision : 0.704, Recall : 0.885, F1 : 0.784\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  335\n",
      "False Positives per class :  220\n",
      "False Negatives per class :  81\n",
      "Accuracy : 0.7993, Precision : 0.604, Recall : 0.805, F1 : 0.690\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  388\n",
      "False Positives per class :  268\n",
      "False Negatives per class :  28\n",
      "Accuracy : 0.8027, Precision : 0.591, Recall : 0.933, F1 : 0.724\n",
      "\n",
      "getting results for fold 35\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  354\n",
      "False Positives per class :  150\n",
      "False Negatives per class :  52\n",
      "Accuracy : 0.8653, Precision : 0.702, Recall : 0.872, F1 : 0.778\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  316\n",
      "False Positives per class :  215\n",
      "False Negatives per class :  90\n",
      "Accuracy : 0.7967, Precision : 0.595, Recall : 0.778, F1 : 0.674\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  376\n",
      "False Positives per class :  265\n",
      "False Negatives per class :  30\n",
      "Accuracy : 0.8033, Precision : 0.587, Recall : 0.926, F1 : 0.718\n",
      "\n",
      "getting results for fold 36\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  362\n",
      "False Positives per class :  184\n",
      "False Negatives per class :  45\n",
      "Accuracy : 0.8473, Precision : 0.663, Recall : 0.889, F1 : 0.760\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  319\n",
      "False Positives per class :  250\n",
      "False Negatives per class :  88\n",
      "Accuracy : 0.7747, Precision : 0.561, Recall : 0.784, F1 : 0.654\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  383\n",
      "False Positives per class :  308\n",
      "False Negatives per class :  24\n",
      "Accuracy : 0.7787, Precision : 0.554, Recall : 0.941, F1 : 0.698\n",
      "\n",
      "getting results for fold 37\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  359\n",
      "False Positives per class :  166\n",
      "False Negatives per class :  37\n",
      "Accuracy : 0.8647, Precision : 0.684, Recall : 0.907, F1 : 0.780\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  308\n",
      "False Positives per class :  234\n",
      "False Negatives per class :  88\n",
      "Accuracy : 0.7853, Precision : 0.568, Recall : 0.778, F1 : 0.657\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  379\n",
      "False Positives per class :  290\n",
      "False Negatives per class :  17\n",
      "Accuracy : 0.7953, Precision : 0.567, Recall : 0.957, F1 : 0.712\n",
      "\n",
      "getting results for fold 38\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  358\n",
      "False Positives per class :  165\n",
      "False Negatives per class :  39\n",
      "Accuracy : 0.8640, Precision : 0.685, Recall : 0.902, F1 : 0.778\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  317\n",
      "False Positives per class :  232\n",
      "False Negatives per class :  80\n",
      "Accuracy : 0.7920, Precision : 0.577, Recall : 0.798, F1 : 0.670\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  381\n",
      "False Positives per class :  284\n",
      "False Negatives per class :  16\n",
      "Accuracy : 0.8000, Precision : 0.573, Recall : 0.960, F1 : 0.718\n",
      "\n",
      "getting results for fold 39\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  357\n",
      "False Positives per class :  165\n",
      "False Negatives per class :  45\n",
      "Accuracy : 0.8600, Precision : 0.684, Recall : 0.888, F1 : 0.773\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  316\n",
      "False Positives per class :  221\n",
      "False Negatives per class :  86\n",
      "Accuracy : 0.7953, Precision : 0.588, Recall : 0.786, F1 : 0.673\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  373\n",
      "False Positives per class :  274\n",
      "False Negatives per class :  29\n",
      "Accuracy : 0.7980, Precision : 0.577, Recall : 0.928, F1 : 0.711\n",
      "\n",
      "getting results for fold 40\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  352\n",
      "False Positives per class :  167\n",
      "False Negatives per class :  47\n",
      "Accuracy : 0.8573, Precision : 0.678, Recall : 0.882, F1 : 0.767\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  165\n",
      "False Positives per class :  385\n",
      "False Negatives per class :  234\n",
      "Accuracy : 0.5873, Precision : 0.300, Recall : 0.414, F1 : 0.348\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  369\n",
      "False Positives per class :  494\n",
      "False Negatives per class :  30\n",
      "Accuracy : 0.6507, Precision : 0.428, Recall : 0.925, F1 : 0.585\n",
      "\n",
      "getting results for fold 41\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  348\n",
      "False Positives per class :  136\n",
      "False Negatives per class :  38\n",
      "Accuracy : 0.8840, Precision : 0.719, Recall : 0.902, F1 : 0.800\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  307\n",
      "False Positives per class :  213\n",
      "False Negatives per class :  79\n",
      "Accuracy : 0.8053, Precision : 0.590, Recall : 0.795, F1 : 0.678\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  360\n",
      "False Positives per class :  257\n",
      "False Negatives per class :  26\n",
      "Accuracy : 0.8113, Precision : 0.583, Recall : 0.933, F1 : 0.718\n",
      "\n",
      "getting results for fold 42\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  337\n",
      "False Positives per class :  163\n",
      "False Negatives per class :  44\n",
      "Accuracy : 0.8620, Precision : 0.674, Recall : 0.885, F1 : 0.765\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  311\n",
      "False Positives per class :  239\n",
      "False Negatives per class :  70\n",
      "Accuracy : 0.7940, Precision : 0.565, Recall : 0.816, F1 : 0.668\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  353\n",
      "False Positives per class :  288\n",
      "False Negatives per class :  28\n",
      "Accuracy : 0.7893, Precision : 0.551, Recall : 0.927, F1 : 0.691\n",
      "\n",
      "getting results for fold 43\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  373\n",
      "False Positives per class :  157\n",
      "False Negatives per class :  47\n",
      "Accuracy : 0.8640, Precision : 0.704, Recall : 0.888, F1 : 0.785\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  349\n",
      "False Positives per class :  224\n",
      "False Negatives per class :  71\n",
      "Accuracy : 0.8033, Precision : 0.609, Recall : 0.831, F1 : 0.703\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  396\n",
      "False Positives per class :  277\n",
      "False Negatives per class :  24\n",
      "Accuracy : 0.7993, Precision : 0.588, Recall : 0.943, F1 : 0.725\n",
      "\n",
      "getting results for fold 44\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  377\n",
      "False Positives per class :  185\n",
      "False Negatives per class :  39\n",
      "Accuracy : 0.8507, Precision : 0.671, Recall : 0.906, F1 : 0.771\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  340\n",
      "False Positives per class :  219\n",
      "False Negatives per class :  76\n",
      "Accuracy : 0.8033, Precision : 0.608, Recall : 0.817, F1 : 0.697\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  394\n",
      "False Positives per class :  279\n",
      "False Negatives per class :  22\n",
      "Accuracy : 0.7993, Precision : 0.585, Recall : 0.947, F1 : 0.724\n",
      "\n",
      "getting results for fold 45\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  358\n",
      "False Positives per class :  169\n",
      "False Negatives per class :  45\n",
      "Accuracy : 0.8573, Precision : 0.679, Recall : 0.888, F1 : 0.770\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  332\n",
      "False Positives per class :  208\n",
      "False Negatives per class :  71\n",
      "Accuracy : 0.8140, Precision : 0.615, Recall : 0.824, F1 : 0.704\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  386\n",
      "False Positives per class :  264\n",
      "False Negatives per class :  17\n",
      "Accuracy : 0.8127, Precision : 0.594, Recall : 0.958, F1 : 0.733\n",
      "\n",
      "getting results for fold 46\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  362\n",
      "False Positives per class :  157\n",
      "False Negatives per class :  49\n",
      "Accuracy : 0.8627, Precision : 0.697, Recall : 0.881, F1 : 0.778\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  336\n",
      "False Positives per class :  221\n",
      "False Negatives per class :  75\n",
      "Accuracy : 0.8027, Precision : 0.603, Recall : 0.818, F1 : 0.694\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  381\n",
      "False Positives per class :  265\n",
      "False Negatives per class :  30\n",
      "Accuracy : 0.8033, Precision : 0.590, Recall : 0.927, F1 : 0.721\n",
      "\n",
      "getting results for fold 47\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  324\n",
      "False Positives per class :  168\n",
      "False Negatives per class :  37\n",
      "Accuracy : 0.8633, Precision : 0.659, Recall : 0.898, F1 : 0.760\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  298\n",
      "False Positives per class :  233\n",
      "False Negatives per class :  63\n",
      "Accuracy : 0.8027, Precision : 0.561, Recall : 0.825, F1 : 0.668\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  345\n",
      "False Positives per class :  286\n",
      "False Negatives per class :  16\n",
      "Accuracy : 0.7987, Precision : 0.547, Recall : 0.956, F1 : 0.696\n",
      "\n",
      "getting results for fold 48\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  364\n",
      "False Positives per class :  165\n",
      "False Negatives per class :  49\n",
      "Accuracy : 0.8573, Precision : 0.688, Recall : 0.881, F1 : 0.773\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  342\n",
      "False Positives per class :  201\n",
      "False Negatives per class :  71\n",
      "Accuracy : 0.8187, Precision : 0.630, Recall : 0.828, F1 : 0.715\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  385\n",
      "False Positives per class :  261\n",
      "False Negatives per class :  28\n",
      "Accuracy : 0.8073, Precision : 0.596, Recall : 0.932, F1 : 0.727\n",
      "\n",
      "getting results for fold 49\n",
      "bert result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  363\n",
      "False Positives per class :  173\n",
      "False Negatives per class :  45\n",
      "Accuracy : 0.8547, Precision : 0.677, Recall : 0.890, F1 : 0.769\n",
      "hapy result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  327\n",
      "False Positives per class :  224\n",
      "False Negatives per class :  81\n",
      "Accuracy : 0.7967, Precision : 0.593, Recall : 0.801, F1 : 0.682\n",
      "max result\n",
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  387\n",
      "False Positives per class :  288\n",
      "False Negatives per class :  21\n",
      "Accuracy : 0.7940, Precision : 0.573, Recall : 0.949, F1 : 0.715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_summary_bert = []\n",
    "result_summary_hapy = []\n",
    "result_summary_hapyORbert = []\n",
    "\n",
    "for i in range (50):\n",
    "    \n",
    "    print(\"getting results for fold\", i)\n",
    "    \n",
    "    input_path = \"/data/SuperMod/testfolds/fold\" + str(i) + \".csv\"\n",
    "    result_path_hapy = \"/data/SuperMod/infer_result_fold\" + str(i) + \".pkl\"\n",
    "    result_path_bert = \"/data/SuperMod/raw/fold\"  + str(i) + \".csv\"\n",
    "    \n",
    "    input_df = pd.read_csv(input_path)\n",
    "    \n",
    "    with open(result_path_hapy, 'rb') as w:\n",
    "        hapy_result = pkl.load(w)\n",
    "    bert_df = pd.read_csv(result_path_bert)\n",
    "    bert_result =  bert_df.supermod_inferred_results\n",
    "    max_bert_hapy = np.maximum(bert_result, hapy_result)\n",
    "    \n",
    "    actual = input_df.toxicity\n",
    "    \n",
    "#     print(\"bert\")\n",
    "#     print(bert_result[:5])\n",
    "#     print(\"hapy\")\n",
    "#     print(hapy_result[:5])\n",
    "#     print(\"max_bert_hapy\")\n",
    "#     print(max_bert_hapy[:5])\n",
    "    \n",
    "    input_df[\"bert_result\"] = bert_result\n",
    "    input_df[\"hapy_result\"] = hapy_result    \n",
    "    input_df[\"max_bert_hapy\"] = max_bert_hapy   \n",
    "    \n",
    "    print(\"bert result\")\n",
    "    ab, pb, rb, fb = get_metrics(np.asarray(actual), np.asarray(bert_result))  \n",
    "    print(\"hapy result\")    \n",
    "    ah, ph, rh, fh = get_metrics(np.asarray(actual), np.asarray(hapy_result))    \n",
    "    print(\"max result\")     \n",
    "    am, pm, rm, fm = get_metrics(np.asarray(actual), np.asarray(max_bert_hapy))\n",
    "    \n",
    "    aucb = roc_auc_score(actual, bert_result)\n",
    "    auch = roc_auc_score(actual, hapy_result) \n",
    "    aucm = roc_auc_score(actual, max_bert_hapy) \n",
    "    \n",
    "    \n",
    "    apsb = average_precision_score(actual, bert_result)\n",
    "    apsh = average_precision_score(actual, hapy_result) \n",
    "    apsm = average_precision_score(actual, max_bert_hapy) \n",
    "    \n",
    "    result_summary_bert.append([ ab, pb, rb, fb, aucb, apsb])\n",
    "    result_summary_hapy.append([ ah, ph, rh, fh, auch, apsh])\n",
    "    result_summary_hapyORbert.append([ am, pm, rm, fm, aucm, apsm])    \n",
    "    \n",
    "    save_path = \"/data/SuperMod/full_result_raw/fold\" + str(i) + \".csv\"\n",
    "    print()\n",
    "    \n",
    "    input_df = input_df.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "    input_df.to_csv(save_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>bert_result</th>\n",
       "      <th>hapy_result</th>\n",
       "      <th>max_bert_hapy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" \\n\\n == Homer's \"\"Official\"\" Age == \\n\\n Acc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057445</td>\n",
       "      <td>0.033922</td>\n",
       "      <td>0.057445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>== WP:RS == \\n\\n Someone has added a BLOG as a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.379510</td>\n",
       "      <td>0.110729</td>\n",
       "      <td>0.379510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Being a psychopath I would have to tell you al...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987681</td>\n",
       "      <td>0.976389</td>\n",
       "      <td>0.987681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DIS NIGGA IS GAY HE KILLED LOTS OF FUQIN PPL T...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998390</td>\n",
       "      <td>0.681788</td>\n",
       "      <td>0.998390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>빨리 차단 해제하라! 그렇지 않으면 범칙금 10만 원이야. 병신아. 차단 빨리 해제하라.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.081212</td>\n",
       "      <td>0.444230</td>\n",
       "      <td>0.444230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxicity  bert_result  \\\n",
       "0  \" \\n\\n == Homer's \"\"Official\"\" Age == \\n\\n Acc...         0     0.057445   \n",
       "1  == WP:RS == \\n\\n Someone has added a BLOG as a...         0     0.379510   \n",
       "2  Being a psychopath I would have to tell you al...         0     0.987681   \n",
       "3  DIS NIGGA IS GAY HE KILLED LOTS OF FUQIN PPL T...         1     0.998390   \n",
       "4  빨리 차단 해제하라! 그렇지 않으면 범칙금 10만 원이야. 병신아. 차단 빨리 해제하라.         0     0.081212   \n",
       "\n",
       "   hapy_result  max_bert_hapy  \n",
       "0     0.033922       0.057445  \n",
       "1     0.110729       0.379510  \n",
       "2     0.976389       0.987681  \n",
       "3     0.681788       0.998390  \n",
       "4     0.444230       0.444230  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test save:\n",
    "save_path = \"/data/SuperMod/full_result_raw/fold1.csv\"\n",
    "save_file = pd.read_csv(save_path)\n",
    "save_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.854,\n",
       "  0.6765799256505576,\n",
       "  0.9356930117274253,\n",
       "  0.7687434002111933,\n",
       "  0.9356930117274253],\n",
       " [0.8553333333333333,\n",
       "  0.6867030965391621,\n",
       "  0.9313081975573512,\n",
       "  0.7765190525231719,\n",
       "  0.9313081975573512],\n",
       " [0.852,\n",
       "  0.6754221388367729,\n",
       "  0.9344716383659144,\n",
       "  0.7643312101910826,\n",
       "  0.9344716383659144],\n",
       " [0.844,\n",
       "  0.6547842401500938,\n",
       "  0.9269222101575465,\n",
       "  0.7489270386266095,\n",
       "  0.9269222101575465],\n",
       " [0.862,\n",
       "  0.6996336996336996,\n",
       "  0.9494369357045145,\n",
       "  0.7868177136972193,\n",
       "  0.9494369357045145]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_summary_bert[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8153333333333334,\n",
       "  0.6245283018867924,\n",
       "  0.8771858661329974,\n",
       "  0.7050053248136317,\n",
       "  0.8771858661329974],\n",
       " [0.806,\n",
       "  0.612736660929432,\n",
       "  0.8947563945871325,\n",
       "  0.7098703888334996,\n",
       "  0.8947563945871325],\n",
       " [0.7986666666666666,\n",
       "  0.5974499089253188,\n",
       "  0.8832210192752885,\n",
       "  0.6847599164926931,\n",
       "  0.8832210192752885],\n",
       " [0.8,\n",
       "  0.5950095969289827,\n",
       "  0.8659250305600514,\n",
       "  0.6739130434782609,\n",
       "  0.8659250305600514],\n",
       " [0.8033333333333333,\n",
       "  0.6164874551971327,\n",
       "  0.8905061559507523,\n",
       "  0.6998982706002035,\n",
       "  0.8905061559507523]]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_summary_hapy[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8006666666666666,\n",
       "  0.5843558282208589,\n",
       "  0.931719626461446,\n",
       "  0.7181903864278981,\n",
       "  0.931719626461446],\n",
       " [0.7953333333333333,\n",
       "  0.5849335302806499,\n",
       "  0.9330206016055711,\n",
       "  0.7206551410373065,\n",
       "  0.9330206016055711],\n",
       " [0.7993333333333333,\n",
       "  0.5808383233532934,\n",
       "  0.933113560829996,\n",
       "  0.7205199628597957,\n",
       "  0.933113560829996],\n",
       " [0.792,\n",
       "  0.5656108597285068,\n",
       "  0.924789266536004,\n",
       "  0.7062146892655368,\n",
       "  0.924789266536004],\n",
       " [0.7966666666666666,\n",
       "  0.5879765395894428,\n",
       "  0.9403666210670315,\n",
       "  0.7244805781391148,\n",
       "  0.9403666210670315]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_summary_hapyORbert[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am</th>\n",
       "      <th>pm</th>\n",
       "      <th>rm</th>\n",
       "      <th>fm</th>\n",
       "      <th>aucm</th>\n",
       "      <th>apsm</th>\n",
       "      <th>ab</th>\n",
       "      <th>pb</th>\n",
       "      <th>rb</th>\n",
       "      <th>fb</th>\n",
       "      <th>aucb</th>\n",
       "      <th>apsb</th>\n",
       "      <th>ah</th>\n",
       "      <th>ph</th>\n",
       "      <th>rh</th>\n",
       "      <th>fh</th>\n",
       "      <th>auch</th>\n",
       "      <th>apsh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800667</td>\n",
       "      <td>0.584356</td>\n",
       "      <td>0.931540</td>\n",
       "      <td>0.718190</td>\n",
       "      <td>0.931720</td>\n",
       "      <td>0.846725</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.676580</td>\n",
       "      <td>0.889976</td>\n",
       "      <td>0.768743</td>\n",
       "      <td>0.935693</td>\n",
       "      <td>0.850100</td>\n",
       "      <td>0.815333</td>\n",
       "      <td>0.624528</td>\n",
       "      <td>0.809291</td>\n",
       "      <td>0.705005</td>\n",
       "      <td>0.877186</td>\n",
       "      <td>0.720810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.795333</td>\n",
       "      <td>0.584934</td>\n",
       "      <td>0.938389</td>\n",
       "      <td>0.720655</td>\n",
       "      <td>0.933021</td>\n",
       "      <td>0.852093</td>\n",
       "      <td>0.855333</td>\n",
       "      <td>0.686703</td>\n",
       "      <td>0.893365</td>\n",
       "      <td>0.776519</td>\n",
       "      <td>0.931308</td>\n",
       "      <td>0.849463</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.612737</td>\n",
       "      <td>0.843602</td>\n",
       "      <td>0.709870</td>\n",
       "      <td>0.894756</td>\n",
       "      <td>0.786841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.799333</td>\n",
       "      <td>0.580838</td>\n",
       "      <td>0.948655</td>\n",
       "      <td>0.720520</td>\n",
       "      <td>0.933114</td>\n",
       "      <td>0.844299</td>\n",
       "      <td>0.852000</td>\n",
       "      <td>0.675422</td>\n",
       "      <td>0.880196</td>\n",
       "      <td>0.764331</td>\n",
       "      <td>0.934472</td>\n",
       "      <td>0.844636</td>\n",
       "      <td>0.798667</td>\n",
       "      <td>0.597450</td>\n",
       "      <td>0.801956</td>\n",
       "      <td>0.684760</td>\n",
       "      <td>0.883221</td>\n",
       "      <td>0.728499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.565611</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.706215</td>\n",
       "      <td>0.924789</td>\n",
       "      <td>0.820564</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.654784</td>\n",
       "      <td>0.874687</td>\n",
       "      <td>0.748927</td>\n",
       "      <td>0.926922</td>\n",
       "      <td>0.817609</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.595010</td>\n",
       "      <td>0.776942</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.865925</td>\n",
       "      <td>0.723623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.796667</td>\n",
       "      <td>0.587977</td>\n",
       "      <td>0.943529</td>\n",
       "      <td>0.724481</td>\n",
       "      <td>0.940367</td>\n",
       "      <td>0.881744</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.699634</td>\n",
       "      <td>0.898824</td>\n",
       "      <td>0.786818</td>\n",
       "      <td>0.949437</td>\n",
       "      <td>0.885824</td>\n",
       "      <td>0.803333</td>\n",
       "      <td>0.616487</td>\n",
       "      <td>0.809412</td>\n",
       "      <td>0.699898</td>\n",
       "      <td>0.890506</td>\n",
       "      <td>0.792453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         am        pm        rm        fm      aucm      apsm        ab  \\\n",
       "0  0.800667  0.584356  0.931540  0.718190  0.931720  0.846725  0.854000   \n",
       "1  0.795333  0.584934  0.938389  0.720655  0.933021  0.852093  0.855333   \n",
       "2  0.799333  0.580838  0.948655  0.720520  0.933114  0.844299  0.852000   \n",
       "3  0.792000  0.565611  0.939850  0.706215  0.924789  0.820564  0.844000   \n",
       "4  0.796667  0.587977  0.943529  0.724481  0.940367  0.881744  0.862000   \n",
       "\n",
       "         pb        rb        fb      aucb      apsb        ah        ph  \\\n",
       "0  0.676580  0.889976  0.768743  0.935693  0.850100  0.815333  0.624528   \n",
       "1  0.686703  0.893365  0.776519  0.931308  0.849463  0.806000  0.612737   \n",
       "2  0.675422  0.880196  0.764331  0.934472  0.844636  0.798667  0.597450   \n",
       "3  0.654784  0.874687  0.748927  0.926922  0.817609  0.800000  0.595010   \n",
       "4  0.699634  0.898824  0.786818  0.949437  0.885824  0.803333  0.616487   \n",
       "\n",
       "         rh        fh      auch      apsh  \n",
       "0  0.809291  0.705005  0.877186  0.720810  \n",
       "1  0.843602  0.709870  0.894756  0.786841  \n",
       "2  0.801956  0.684760  0.883221  0.728499  \n",
       "3  0.776942  0.673913  0.865925  0.723623  \n",
       "4  0.809412  0.699898  0.890506  0.792453  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapyORbert = pd.DataFrame(result_summary_hapyORbert, columns=[\"am\", \"pm\", \"rm\", \"fm\", \"aucm\", \"apsm\"])\n",
    "bert = pd.DataFrame(result_summary_bert, columns=[\"ab\", \"pb\", \"rb\", \"fb\", \"aucb\", \"apsb\"])\n",
    "hapy = pd.DataFrame(result_summary_hapy, columns=[\"ah\", \"ph\", \"rh\", \"fh\", \"auch\", \"apsh\"])\n",
    "combined_result = pd.concat([hapyORbert, bert, hapy], axis = 1) \n",
    "combined_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6776556714011595"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(combined_result.fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049574886697035365"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(combined_result.fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7749142739289332"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(combined_result.fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6776556714011595 0.7749142739289332 0.7121174198734204\n"
     ]
    }
   ],
   "source": [
    "print(np.average(combined_result.fh) , np.average(combined_result.fb), np.average(combined_result.fm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049574886697035365 0.01222896593573934 0.02177639846778865\n"
     ]
    }
   ],
   "source": [
    "print(np.std(combined_result.fh) , np.std(combined_result.fb), np.std(combined_result.fm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7988880468031704 0.888129093615743 0.9388387985368273\n"
     ]
    }
   ],
   "source": [
    "print(np.average(combined_result.rh) , np.average(combined_result.rb), np.average(combined_result.rm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.057936867677530084 0.00973319075969664 0.009310331025238951\n"
     ]
    }
   ],
   "source": [
    "print(np.std(combined_result.rh) , np.std(combined_result.rb), np.std(combined_result.rm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5886595211497362 0.6875221308739211 0.5740559864754873\n"
     ]
    }
   ],
   "source": [
    "print(np.average(combined_result.ph) , np.average(combined_result.pb), np.average(combined_result.pm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04527565037484016 0.01788585731321254 0.025818642080578404\n"
     ]
    }
   ],
   "source": [
    "print(np.std(combined_result.ph) , np.std(combined_result.pb), np.std(combined_result.pm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7969466666666666 0.86208 0.79668\n"
     ]
    }
   ],
   "source": [
    "print(np.average(combined_result.ah) , np.average(combined_result.ab), np.average(combined_result.am))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03119033753513346 0.00850687565051549 0.022410509439397704\n"
     ]
    }
   ],
   "source": [
    "print(np.std(combined_result.ah) , np.std(combined_result.ab), np.std(combined_result.am))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8755411783370467 0.938753691632712 0.9332629221063735\n"
     ]
    }
   ],
   "source": [
    "print(np.average(combined_result.auch) , np.average(combined_result.aucb), np.average(combined_result.aucm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06782382342071624 0.015357630666154642 0.019802952659245684\n"
     ]
    }
   ],
   "source": [
    "print(np.std(combined_result.apsh) , np.std(combined_result.apsb), np.std(combined_result.apsm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.739418631615261 0.8499040795307711 0.8461757376392839\n"
     ]
    }
   ],
   "source": [
    "print(np.average(combined_result.apsh) , np.average(combined_result.apsb), np.average(combined_result.apsm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.std(combined_result.auch) , np.std(combined_result.aucb), np.std(combined_result.aucm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEGCAYAAAB8Ys7jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd3hU173u8e9vRg111DuiSPQumsG4EBI7xzXudhIcOyE9Tpzm3HtPyz25x7n3npN+nBCX4MSFGDdc4phgDNimiSY6AoFQ7wV1jWadPzTYBGOrTNlTfp/n4ZmikebVtvR6a+291xJjDEoppQKPzeoASimlRkcLXCmlApQWuFJKBSgtcKWUClBa4EopFaDCfPlmKSkpJj8/35dvqZRSAW/Pnj2NxpjUi5/3aYHn5+dTXFzsy7dUSqmAJyLll3peh1CUUipAaYErpVSA0gJXSqkApQWulFIBSgtcKaUClBa4UkoFKC1wpZQKUFrgSikVoLTAlVIqQPn0SkylfOHpnWd99l53L8rz2XspdTHdA1dKqQClBa6UUgFKC1wppQKUFrhSSgUoLXCllApQWuBKKRWgtMCVUipAaYErpVSA0gJXSqkApQWulFIBSgtcKaUC1JAFLiKTRWT/Bf/aReTbIpIkIhtFpNR1O9YXgZVSSg0assCNMceNMXOMMXOA+UAX8CLwELDJGFMAbHI9Vkop5SMjHUJZAZwyxpQDNwJrXc+vBW7yZDCllFIfb6TTyd4JPOO6n26MqQEwxtSISJpHk6mg4sspXpUKFcPeAxeRCOAG4LmRvIGIrBaRYhEpbmhoGGk+pZRSH2EkQyjXAnuNMXWux3Uikgnguq2/1CcZY9YYY4qMMUWpqanupVVKKfW+kRT4XXwwfAKwAVjlur8KeNlToZRSSg1tWAUuItHASuCFC55+GFgpIqWujz3s+XhKKaU+yrAOYhpjuoDki55rYvCsFKWUUhbQKzGVUipAaYErpVSA0gJXSqkApQWulFIBSgtcKaUClBa4UkoFKC1wpZQKUFrgSikVoEY6G6FSAc0YQ3ffAK3d/YTbbcRE2ImKsGMTsTqaUiOmBa6CXkevg6M17RypbudMUye9DufffTwmMoypGXHMyE6gIC0W0TJXAUILXAWtpo5etpU2svdsCw6nYWx0OLNzE0mNjSRhTDgOp6Gz10FFSxcHq9ooLm8hLyma62ZlkjM22ur4Sg1JC1wFne6+Ad48Usuu083YbcK8vLEsHJ9EZkLUR+5dOwac7K9o5c0jdfzX26dYOjGZa2dm6tCK8mta4CpoGGPYX9HKawdr6O4bYNGEZK6cnEp8VPiQnxtmt1GUn8SM7AT+eriWd0810dTZxx1FuUSG232QXqmR0wJXQaGr18FL+6s4VN1OXlI0N87JIjNhzIi/TlS4nRvnZJMeH8WrJdX8flsZ9y+bwJgILXHlf7TAVcArb+rkmV1n6ewd4JrpGSwrSHF76GPxhGQSo8P5045yntpZzr1L8wmz6Vm3yr/oT6QKWMYYdpQ18ei204TZbXzlyoksL0z12Lj1lIx4PjMvh7LGTl7YW4UxxiNfVylP0T1wFZAGnIZXDlSz60wzk9PjuL0o1yvDHPPyxtLW3c/GI3VkJkRxeYGu66r8hxa4Cjh9DifP7j7LsdpzLC9I5ZPT0716tsiVhalUtXTz5pE6JqXFjmpsXSlv0CEUFVA6eh089k4Zx2vPccPsLK6ZkeH1U/1EhJvnZhMdbmfd7gr6B5xDf5JSPjDcRY0TRWS9iBwTkaMiskREkkRko4iUum7HejusCm1NHb38bsspatp6uGdRHosnJA/9SR4SExnGLfNzqD/Xy8YjdT57X6U+znD3wH8BvGGMmQLMBo4CDwGbjDEFwCbXY6W8oqatm99uLaOrb4D7l41nWlaCzzMUpsexMD+J9041Utve4/P3V+piQxa4iMQDy4HHAIwxfcaYVuBGYK3rZWuBm7wVUoW2mrbuwTNNbMJXrpjIuOQYy7J8clo6kWF2Xi2p1rNSlOWGswc+AWgAnhCRfSLyqIjEAOnGmBoA123apT5ZRFaLSLGIFDc0NHgsuAoN1a2D5R0RZuOLy8aTGhdpaZ7oyDA+MS2dsoZODle3W5pFqeEUeBgwD3jEGDMX6GQEwyXGmDXGmCJjTFFqqp6CpYavurWbx94ZLO8vXT6B5Fhry/u8hflJZMRH8fqhGnr6B6yOo0LYcAq8Eqg0xux0PV7PYKHXiUgmgOu23jsRVSi6uLyTYiKsjvQ+u0349MxMWrv6eXrnWavjqBA2ZIEbY2qBChGZ7HpqBXAE2ACscj23CnjZKwlVyKlr7/Hb8j5vUlos41NieGTLKd0LV5YZ7lko3wSeEpESYA7wf4CHgZUiUgqsdD1Wyi2tXX384b0zhNmELy4b75flfd6KqWk0nOvlTzvKrY6iQtSwrsQ0xuwHii7xoRWejaNCWVefgz+8d4ae/gG/GvP+KBNSYlkyIZnfbinjnkXjdMZC5XN6JabyC/0DTv64vZymzj4+u3gcWYmBcbn6d1YW0tjRy1M7dS9c+Z4WuLLcgNPw7K6znG3u4vaiXCamxlodadgWjk9i0fgkHn/nNA69xF75mBa4spQxhg0Hqjlae47rZmcxM9v3V1i660uXT6C6rYfXD9VaHUWFGC1wZantZU3sPtPMFYWpLPHh3CaedPWUNManxPDotjK9OlP5lBa4skxZQwevH6xhSkYcK6elWx1n1Gw24b5l4ympHFzZXilf0QJXlmjp6uPpXWdJjonk9qLcgF/9/ZZ52SRGh/P7rWVWR1EhRAtc+Vyfw8mfdpTjNIbPLR5HVBCs+h4dEcbdC/PYeLSOypYuq+OoEKEFrnzKGMML+yqpbevhjqJcUiyenMqT7l6UB8C63RUWJ1GhQgtc+dQ7JxspqWxj5bR0JmfEWx3Ho3LGRnNlYaqu2qN8Rgtc+czZ5i7+eriW6VnxXFEYnDNT3rNoHPXnetl0VFftUd6nBa58ortvgHW7z5IwJpzPzM1BAvyg5Ue5akoaWQlRPKWzFCof0AJXXmeM4cX9VbR193PHgrygnjPEbhPuXJjHttJGyps6rY6jgpwWuPK6F/ZWcaiqjZXTMshLirY6jtfdsSAXm8BzxZVWR1FBTgtceVVVazf/suEw+cnRXF6QYnUcn0iPj2J5YSrP761kwKlXZirv0QJXXuN0Gn6w/gADxnDr/MC/WGckbp2fQ01bD9tPNVkdRQUxLXDlNU/tLOfdk03843XT/HphBm/4xNR04qPCWL9HzwlX3qMFrryipq2bn75xnMsLUrhzQa7VcXwuKtzODXOyeONwLe09/VbHUUFKC1x5nDGGf3zpEA6nk5/cNDNoTxkcyq3zc+npd/J6SY3VUVSQGlaBi8gZETkoIvtFpNj1XJKIbBSRUtftWO9GVYHi9YO1/O1oPd9dOZm85OA/6+SjzM5JYFJaLM/v1bNRlHeMZA/8KmPMHGPM+bUxHwI2GWMKgE2uxyrEnevp519fOcyM7Hi+sDTf6jiWEhFunJ3F7jMtVLV2Wx1HBSF3hlBuBNa67q8FbnI/jgp0v3rrJA0dvfzkppmE2XWE7vrZWQC8eqDa4iQqGA33N8wAb4rIHhFZ7Xou3RhTA+C6TbvUJ4rIahEpFpHihoYG9xMrv3Wy/hyPv3Oa2+fnMjs30eo4fiE/JYbZOQm8UqIFrjxvuAW+1BgzD7gW+LqILB/uGxhj1hhjiowxRampwTmBkRo8cPmvrxxhTISd718z2eo4fuX62VkcqmqnrKHD6igqyAyrwI0x1a7beuBFYCFQJyKZAK7bem+FVP7vb0fr2VbayIMrC0mJDZ45vj3hullZiMArB/RsFOVZQxa4iMSISNz5+8AngUPABmCV62WrgJe9FVL5N8eAk4f/cpQJqTF8dvE4q+P4nYyEKBbmJ7HhQJUueqw8KmwYr0kHXnSdyxsGPG2MeUNEdgN/FpH7gbPAbd6LqfzZuuIKTjV0suZz8wkPsQOXTw9z2tiMhCh2nm7mP948QVbimFG91/kVf5Q6b8gCN8aUAbMv8XwTsMIboVTg6Ox18LONpSzIHxvQK8t724ysBF45UE1JZduoC1ypi4XW7pLyuEe3naaxo5cffXpqyF5xORwxkWFMSoulpKpVh1GUx2iBq1Fr7erj0W1lXDM9g3l5eiHuUGblJNLa1U9Fs65arzxDC1yN2u+3ldHR5+A7KwutjhIQpmXGE2YTDlS2WR1FBQktcDUqzZ19PPHuGa6blcXkjDir4wSEqHA7kzPiOFjVpgs9KI/QAlej8rutp+jpH+CBFQVWRwkos3IS6eh1cLpR18tU7tMCVyPW1NHLk++Vc+OcbCalxVodJ6BMyYgjIsxGSWWr1VFUENACVyP2xLtn6HEM8PWrJlkdJeCE221MyYjjSE27DqMot2mBqxE519PP2u1nuGZ6hu59j9LM7AS6+gZ0GEW5TQtcjchTO89yrsfB167Uve/RKkyPI8Ju42CVno2i3KMFroatp3+AR7ed5vKCFGbmJFgdJ2CF221MzojjSLWejaLcowWuhm39nkoaO3r56pUTrY4S8GZmJ9DZN8CZJh1GUaOnBa6Gxek0PP7OaWblJLBkQrLVcQJeYXoc4XbRYRTlluHMRqiC1HBn0gM4VttOWWMndxTl8syuCi+mCg0RYTYmZ8RzuLqdG2ZnYdN5ZNQo6B64GpZ3TjaSMCacGdk69u0pM7MT6Ox1cEbPRlGjpAWuhlTd2k1ZQydLJiRjt+meoqdM1mEU5SYtcDWk9041Em4XFuQnWR0lqESE2ShMj+NwdTtOnWJWjYIWuPpYHb0ODlS2MS9vLGMi7FbHCTozsxPo6HVQ3qRTzKqR0wJXH2vPmWYGnIbFeuaJV0zOiCPMpsMoanSGXeAiYheRfSLyquvxeBHZKSKlIrJORCK8F1NZwWkMO880MyElhvT4KKvjBKXIMLtrGKVNh1HUiI1kD/wB4OgFj38K/MwYUwC0APd7Mpiy3vHac7R29bNI9769amZ2Aud6HJzVYRQ1QsMqcBHJAf4BeNT1WICrgfWul6wFbvJGQGWdHWVNxEeFMS0z3uooQW3K+WGUah1GUSMz3D3wnwM/AJyux8lAqzHG4XpcCWR7OJuyUFNHL6X1HSzIT9JTB70sMtw1jFKlwyhqZIYscBG5Dqg3xuy58OlLvPSSP3kislpEikWkuKGhYZQxla8Vl7cgQJGeOugTM7Ljae9x6ILHakSGswe+FLhBRM4AzzI4dPJzIFFEzl+KnwNUX+qTjTFrjDFFxpii1NRUD0RW3jbgNOw928LkjDgSxoRbHSckTMkYXPD4kJ6NokZgyAI3xvzIGJNjjMkH7gTeMsbcA2wGbnW9bBXwstdSKp86UXeOcz0OisaNtTpKyIgKt1OQFsshvahHjYA754H/EHhQRE4yOCb+mGciKasVl7cQGxnG5Aw9eOlLM7ITaOvup1KHUdQwjWg2QmPM28DbrvtlwELPR1JWOtfTz/HadpZOStGDlz42NTMeu004VN1OXnKM1XFUANArMdXf2Xu2FaeBonF68NLX3h9GqWrD6DCKGgYtcPU+Ywx7ypsZlxxNalyk1XFC0ozsBFq7+6ls6bY6igoAWuDqfWeaumjs6NO9bwtNzYjHLno2ihoeLXD1vj3lzUSG2ZipizZYZkyEnUlpsRys1mEUNTQtcAUMrjh/sKqNWTkJRITpj4WVZmQn0NrVT1WrDqOoj6e/qQqAkso2+geMDp/4gamZcdgEHUZRQ9ICVwAUlzeTHh9JztgxVkcJedERYYPDKHo2ihqCFriirr2HypZu5o9LQnR1dL8wIyuBlq5+qlt7rI6i/JgWuGJ/RSs2gdk5evDSX0zLjMcm6Eo96mNpgYc4pzHsr2ilIC2OuCiduMpfREeGMTE1lkN6Nor6GFrgIe50Yydt3f3MyUu0Ooq6yIzsBJo7+6hp02EUdWla4CFu/9lWIsNsuuqOH9JhFDUULfAQ1udwcrC6jRlZCYTb9UfB38REhjEhRedGUR9Nf2tD2NGadvocTh0+8WMzshNo6uyjtl2HUdSHaYGHsH0VLSSMCWd8ik5d6q+mZcUjwMFKHUZRH6YFHqIazvVysr6DObmJ2PTcb78VGzl4Uc+BylYdRlEfogUeojYcqMZpYG6uDp/4uzm5ibR09bOnvMXqKMrPaIGHqBf3VZKdOIa0+Ciro6ghTMuMJ9wuvLS/yuooys9ogYegE3XnOFTVzhzd+w4IkeF2pmbG81pJDf0DTqvjKD8yZIGLSJSI7BKRAyJyWET+1fX8eBHZKSKlIrJORCK8H1d5wgt7q7DbhNla4AFjTs7gMMrWEw1WR1F+ZDh74L3A1caY2cAc4BoRWQz8FPiZMaYAaAHu915M5SlOp+Hl/VUsL0ghNnJEa1orCxWkxzE2OpyX9ldbHUX5kSEL3AzqcD0Md/0zwNXAetfza4GbvJJQedSO003UtPVw87wcq6OoEbDbhOtmZfHm4Vrae/qtjqP8xLDGwEXELiL7gXpgI3AKaDXGOFwvqQSyP+JzV4tIsYgUNzTon39We3FvFbGRYXxyWrrVUdQI3To/h16Hk9dKaqyOovzEsArcGDNgjJkD5AALgamXetlHfO4aY0yRMaYoNTV19EmV27r7BvjLoVqunZFBVLjd6jhqhGblJFCQFstzxRVWR1F+YkRnoRhjWoG3gcVAooicH0TNAXRwzs/97WgdHb0Obp57yT+WlJ8TEW4rymHv2VZO1ncM/Qkq6A3nLJRUEUl03R8DfAI4CmwGbnW9bBXwsrdCKs94cV8VmQlRLJ6QbHUUNUo3zc3GbhPW76m0OoryA8PZA88ENotICbAb2GiMeRX4IfCgiJwEkoHHvBdTuauxo5ctJxq4cU42NpteOh+o0uKiuLIwlRf3VTLg1EvrQ92Q55EZY0qAuZd4vozB8XAVAF45UM2A0/CZeTp8EuhunZ/DpmP1bD3RwFVT0qyOoyykV2KGiJf2VTEtM57C9Diroyg3rZiaTkpsBE/tPGt1FGUxLfAQcKqhgwOVbbr3HSQiwmzcVpTLW8fqqGnrtjqOspAWeAh4cW8VNoEbZmdZHUV5yF0L8jDAs7v0lMJQpgUe5JxOw0v7q1g6KUVnHgwiecnRXF6QyrrdFTh0gquQpQUe5IrLW6hs6dbhkyB0z6I8att72Hxcr3AOVVrgQe7FfZVER9j51PQMq6MoD1sxJY30+Eie3H7G6ijKIlrgQaynf4BXS2q4ZnoG0RE682CwCbPb+OyicWwrbaS07pzVcZQFtMCD2OZj9ZzrcXCTXjoftO5ZPI7IMBuPv3vG6ijKAlrgQeyFfVWkxUWydFKK1VGUlyTFRPCZedm8sLeS5s4+q+MoH9MCD1ItnX28fbyeG+dkYddL54PafUvH0+tw8vTOcqujKB/TAg9Srx6soX/A6PBJCChIj+PyghSe3F5Or2PA6jjKh7TAg9SLeyuZnB7HtMx4q6MoH1i9fAL153p5Ya+uXB9KtMCDUFlDB3vPtnLzvGxEdPgkFCyblMLsnAT+6+2TemFPCNECD0Lriiuw20Qv3gkhIsI3ry6gormbl3Xh45ChBR5k+gecPL+nkhVT0kiL00vnQ8mKqWlMzYznN2+f1LnCQ4QWeJB561g9jR193LEg1+ooyscG98InUdbQyWsHdeHjUKAFHmTW7a4gPT6SKwp1AelQdM30DCanx/Gfbx6nX8fCg54WeBCpbevh7eP13DY/lzC7/qcNRTab8MNrJ3OmqYtndumCD8FuOIsa54rIZhE5KiKHReQB1/NJIrJRREpdt2O9H1d9nPV7KnAauL1Ih09C2VWT01g8IYlf/K2Ujl6H1XGUFw1nN80BfNcYMxVYDHxdRKYBDwGbjDEFwCbXY2URp9OwrriCyyYmk5ccbXUcZSER4UfXTqWps481W8usjqO8aMgCN8bUGGP2uu6fA44C2cCNwFrXy9YCN3krpBra9rImKpq79eClAmB2biLXzcpkzdZTVDR3WR1HecmIBkpFJJ/BFep3AunGmBoYLHngkstji8hqESkWkeKGBp143lvW7a4gYUy4zvut3vc/Pj0Vmwj/suEwxuhphcFo2AUuIrHA88C3jTHtw/08Y8waY0yRMaYoNVXPjPCGls4+3jhUy81zs4kKt1sdR/mJrMQxfOcThWw6Vs+bR+qsjqO8YFgFLiLhDJb3U8aYF1xP14lIpuvjmUC9dyKqoby0v4q+AacevFQfcu/SfKZkxPEvGw7TqQc0g85wzkIR4DHgqDHmPy/40AZglev+KuBlz8dTQzHG8OyuCmZmJzAtSyeuUn8v3G7jJzfPoLa9h5+8ftTqOMrDhrMHvhT4HHC1iOx3/fs08DCwUkRKgZWux8rHdp5u5njdOT63eJzVUZSfmj8uidXLJ/D0zrP8TYdSgsqQCyUaY94BPmpKuxWejaNGau17Z0iMDueGOVlWR1F+7MGVhWw70cgPny/hjdzlpMZFWh1JeYBerhfAqlu7efNIHXcsyNWDl+pjRYbZ+fmdczjX6+DBP+/Xya6ChBZ4AHtqZznGGD67SIdP1NAK0+P48Q3T2VbayP/96zGr4ygPGHIIRfmnnv4BntlVwYqp6eQm6ZWXanjuXJjHoeo2freljGmZ8dw4R+eMD2S6Bx6gNuyvprmzj1VL8q2OogLMP103nQX5Y/nB+hJ2n2m2Oo5yg+6BByCn07Bm2+Ae1NJJyVbHUQEmIszGbz87n9t+u537/rCbdauXfOgU1Kd3+m4mw7sX5fnsvYKN7oEHoM3H6zlZ38Hq5RN0zUs1Ksmxkfzxi4uIjQzj84/vpKyhw+pIahS0wAPQmq1lZCVE8Q+zMq2OogJYduIY/nj/IoyB23+3g6M1w54hQ/kJLfAAc6CilZ2nm7lv2XjCddEG5aZJabGs+/ISwu3CHb/bzp7yFqsjqRHQBggwj7x9irioMO5cqOOGyjMmpcXy3FeWkBQTwd2/38ErB3RV+0ChBR5Ajta088bhWr5wWT6xkXr8WXlOztho1n/1MmblJPDNZ/ax8UgdTp2C1u9pgQeQX71VSmxkGPctG291FBWEUmIjeeqLi7m9KIfNx+v5w7tnaO/utzqW+hha4AHieO05Xj9Yy72X5ZMYHWF1HBWkIsJs/PSWWdw8N5vy5k5++VapHtz0Y1rgAeKXrr3v+3XvW3mZiLAgP4mvXzWJxDHh/HFHOS/vr6J/wGl1NHURLfAAcLi6jdcP1rDqsnGMjdG9b+UbaXFRfOWKiSyblMLO0838ZvNJKlt0fU1/ogUeAB7+yzESxoSzevlEq6OoEBNmt/HpmZl84bJ8evoH+O2WU/z1cK3ujfsJLXA/t/VEA9tKG/nGVZNIGBNudRwVogrS43hgRSFz88ay5UQDv958Ule79wNa4H7M6TQ8/Jdj5Iwdw+eW6JSxylpjIuzcMi+Hey/Lp8/h5LdbTvHGoRrdG7eQFrgfe2FfFUdq2vn+pyYTGaYLNij/UJgexwMrCijKT2JraSO/euskZ5s6rY4VkoazqPHjIlIvIocueC5JRDaKSKnrdqx3Y4aetq5+/v31o8zNS+T6WbpcmvIvUeF2bp6bzReW5uMYcPK7rWW8frCGPofujfvScC7n+wPwa+DJC557CNhkjHlYRB5yPf6h5+OFnvPTeL68v4rmzj7uWpjHs7srLE6l1KUVpA3ujf/lcC3vnGzkaE07t8zLIT8lxupoIWHIPXBjzFbg4lnfbwTWuu6vBW7ycK6QVtXSza7TzSyekExW4hir4yj1sSLD7dw0J5v7l43HaQy/31bGayXVujfuA6MdA083xtQAuG7TPuqFIrJaRIpFpLihoWGUbxc6BpyGl/ZXERMZxspp6VbHUWrYJqbG8q0VBSyakMS7p5r45VulnG7UsXFv8vpBTGPMGmNMkTGmKDU11dtvF/C2nGigqrWb62dn6UrzKuBEhtm5YXY2X1w2HuPaG3/lgO6Ne8toC7xORDIBXLf1nosUug5Xt/HWsTpm5SQwMzvB6jhKjdqE1FgeWFHIkgnJbC9r4tebT1Ld2m11rKAz2gLfAKxy3V8FvOyZOKGr1zHAd/98gJiIMG7Qs05UEIgIs3H97CzuXzaeXscAj2w5xfZTjRidptZjhnMa4TPAdmCyiFSKyP3Aw8BKESkFVroeKzf85LWjHKs9x81zs4nWub5VEJmYGss3ry5gUmosr5TU8Kcd5XT1OqyOFRSGbApjzF0f8aEVHs4SsjYcqObJ7eV86fLxjE+JtTqOUh4XGxnG55eM471TTbxxqJZfvlXK7QtymaA/727RKzEtdrK+g4eeL6Fo3Fh+cM0Uq+Mo5TUiwtJJKXzlyomE2208tu00fztah0MvxR81LXALNXf28cW1uxkTbufXd8/TRYpVSMhOHMM3rprE3LxE3jpWz12/36EHOEdJG8MiPf0DfOnJYqrbeljz+flkJERZHUkpn4kMt3Pr/Fxum5/Dkep2rv3FNt48XGt1rICjBW6BAafhu88dYE95Cz+7fQ7zxyVZHUkpS8zNG8ur37qc3KQxrP7jHv755UP09A9YHStgaIH7mNNp+OHzJbxWUsOPrp3CP8zKtDqSUpYanxLD81+9jPuWjmft9nJu/q/3OFnfYXWsgKAF7kNOp+F/vnSQ9XsqeWBFAV++QlfYUQoGr+D8p+un8fi9RdS2dXP9r97hueIKPWd8CFrgPtI/4OR76w/wzK4Kvn7VRL79iQKrIynld66eks5fHljO7NwEvr++hAee3U9bV7/VsfyWXjHiA529Dr761F62nmjgwZWFfPPqSYiI1bFUgDk/1XCwy0iI4qkvLuY3m0/yy02l7DzdxMO3zOKqyR85Z17I0j1wL6to7uK2327n3ZONPPyZmXxrRYGWt1JDsNuEb60o4MWvLSVhTDhfeGI3P3qhhA69gvPvaIF70dYTDVz/63eoaOni0c8XcefCPKsjKRVQZuYksOEby/jyFRN4dncF1/x8K++ebLQ6lt/QAveCXscA//6Xo6x6YhcZ8VG88o1lXDVF//xTajSiwu386NqpPPflJYTZhHse3ck3n9lHXXuP1dEsp2PgHjsCVN0AAAmCSURBVHaoqo3vPXeAY7XnuGthLv943TSiI3QzK+Wuovwk3vj2ch55+xSPbDnFW0fr+M7KQlZdlh+yVzFrs3hIe08///nmCZ7cfoakmEgeW1XEiqm6oo5SnhQVbuc7Kwv5zLxs/nnDYf7ttaOs31PJQ9dO4YrC1JA7vqQF7qY+h5Nndp3lV2+V0tTZx2cXjeN7n5xMQnS41dGUClrjkmN44t4FvHmkjh+/coR7n9hN0bixPLiykMsmpVgdz2e0wEepp3+AF/ZW8ciWk1Q0d7NofBKP3zuVWTmJVkdTKiSICJ+ansFVk9NYV1zBb946yd2P7mTxhCQeXDmZheODf4oKLfARqm/vYd3uCtZuL6exo5dZOQn8200zWV6QEnJ/vinlDyLCbHxu8Thum5/DM7vO8pvNp7j9d9uZnZvIfUvzuXZGJhFhwTlGrgU+DL2OAd4+3sCLe6sG5y92GpYXpvKV5RNYMjFZi1spPxAVbucLS8dz54I8/lxcwR/eO8MDz+7nxzFHuGluNrfMy2FqZlxQ/b5qgX+E+vYetpY2svVEA5uP13Oux0FyTAT3LRvPXQvzGJ8SY3VEpdQljImws+qyfD63eBxbShv48+4Kntx+hsfeOU1eUjSfmJrOymnpLMgfS1iAn72iBQ4YY6hq7eZQVRv7zray5UQDx2rPAZASG8mnpmdw/ewslk5MDvj/4EqFCptNuGpyGldNTqOpo5c3Dtey8Ugdf9pRzuPvniYxOpxlk1KYlzeWuXmJTM9KCLihFrcKXESuAX4B2IFHjTF+vbixY8BJTVsPZ5u7ONvcxZmmTo5Ut3Ooqo0W14Q54XahaFwSP7xmCssLU5iaEY/NFjx/cikVipJjI7ln0TjuWTSOjl4H2040sPFIHTvKmni1pAYYHEufkRXPlMx4JqTEMD4lhvyUGHLHRvttsY+6wEXEDvyGwVXpK4HdIrLBGHPEU+HOa+ropbN3gH6nkwGnoX/AiWPA4HA66R8YfNzZ66Cjd4CuPgcdvQ7auvtp6uijubOPpo5eGjv6qGvvweH8YHrKcLtQmB7Hp6ZnMD07gZnZCUzJiCMq3O7pb0Ep5SdiI8O4dmYm184cnIu/tq2HfWdb2FfRyr6zLbxWUkNb9wczINpk8C/x1DjXv9hIkmMjiY20Ex0RRozrNjrig9twu40wu2C3CWG2wdv0+CiPX3Dkzh74QuCkMaYMQESeBW4EPF7g333uAG8fbxjR50TYbSTHRpAUE0FybCQTUmPJSowiLyma3KRo8pKiyUwYg133rpUKaRkJUX9X6AAtnX2cburkdEMnZ5o6qW/vpaGjl4ZzvRyrOUdTZy/9AyObq/xvDy5nUlqcR7O7U+DZQMUFjyuBRRe/SERWA6tdDztE5Lgb7/lRUoAPzXBT6oU3CmCX3Ebq7+g2Gh6Pbqd7PPWF/MuHtlHBT936euMu9aQ7BX6pXdcP/S/JGLMGWOPG+wwdRKTYGFPkzfcIdLqNhqbbaHh0Ow3NV9vInQGZSiD3gsc5QLV7cZRSSg2XOwW+GygQkfEiEgHcCWzwTCyllFJDGfUQijHGISLfAP7K4GmEjxtjDnss2ch4dYgmSOg2Gppuo+HR7TQ0n2wj0VWflVIqMPnn2elKKaWGpAWulFIByq8LXESuEZHjInJSRB66xMfHicgmESkRkbdFJMf1/BwR2S4ih10fu8P36X3Hje00TkT2iMh+17b6iu/T+8Zot9EFH48XkSoR+bXvUvuWO9tIRAZcP0f7RSRoT2ZwcxvlicibInJURI6ISL7bgYwxfvmPwQOjp4AJQARwAJh20WueA1a57l8N/NF1vxAocN3PAmqARKu/Jz/cThFApOt+LHAGyLL6e/KnbXTBx38BPA382urvxx+3EdBh9fcQANvobWCl634sEO1uJn/eA3//Un1jTB9w/lL9C00DNrnubz7/cWPMCWNMqet+NVAPpPokte+5s536jDG9rucj8fO/yNww6m0EICLzgXTgTR9ktYpb2yhEjHobicg0IMwYsxHAGNNhjOlyN5A//8Je6lL97ItecwC4xXX/ZiBORJIvfIGILGTw/5anvJTTam5tJxHJFZES19f4qet/eMFm1NtIRGzAfwDf93pKa7n7+xYlIsUiskNEbvJuVMu4s40KgVYReUFE9onI/3NNCOgWfy7w4Vyq/z3gChHZB1wBVAGO97+ASCbwR+ALxhint4JazK3tZIypMMbMAiYBq0Qk3ZthLeLONvoa8LoxpoLg5u7vW54ZvHT8buDnIjLRa0mt4842CgMud318AYPDMPe6G8ifF3QY8lJ9197iZwBEJBa4xRjT5nocD7wG/C9jzA6fJLaGW9vpwteIyGEGf8jWezWx7416G4nIEuByEfkag+OWESLSYYz50AGsAOfWz9H5v9yMMWUi8jYwl+D7q9edn6NKYJ/5YPbWl4DFwGNuJbL6wMDHHDAIA8qA8XxwwGD6Ra9JAWyu+z8Bfuy6H8HgONS3rf4+/Hw75QBjXPfHAieAmVZ/T/60jS56zb0E70FMd36OxvLBwfAUBicCnear7AGyjeyu16e6Hj8BfN3dTH47hGKMcQDnL9U/CvzZGHNYRH4sIje4XnYlcFxETjB4kOknrudvB5YD915watMc334HvuHmdpoK7BSRA8AW4P8bYw769BvwATe3UUjwwM9RsevnaDPwsPHCwi5Wc2cbGWMGGBw+2SQiBxkcjvm9u5n0UnqllApQfrsHrpRS6uNpgSulVIDSAldKqQClBa6UUgFKC1wppQKUFrhSH0NE8kXkkNU5lLoULXCllApQWuAqqInIS645zw+LyGrXcx0XfPxWEfmD6366iLwoIgdc/y5zvSxMRNa65nheLyLRvv9OlPowLXAV7O4zxswHioBvXTxb5UV+CWwxxswG5gHnF+meDKwxg5N+tTM4wZVSltMCV8HuW65LvHcwOBFRwce89mrgERi89Nl8MOFXhTHmXdf9PwHLvBVWqZHw59kIlXKLiFwJfAJYYozpcs2SF8XfTwEaNYwvdfF8Ezr/hPILugeuglkC0OIq7ykMTt8JUCciU12LNdx8wes3AV8FEBG7a0pigDzXtLIAdwHv+CC7UkPSAlfB7A0GD0CWAP+bwWEUgIeAV4G3GFwv9bwHgKtcs8XtAaa7nj/K4GIXJUASrmEWpaymsxEqpVSA0j1wpZQKUFrgSikVoLTAlVIqQGmBK6VUgNICV0qpAKUFrpRSAUoLXCmlAtR/A8QZ44R0kMczAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.distplot(combined_result.aucb)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_result.to_csv(\"/data/SuperMod/full_result_raw/all_summarized.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test pieces for above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>supermod_inferred_results</th>\n",
       "      <th>supermod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2732</td>\n",
       "      <td>== Your (re)appointment == \\n\\n You have both ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43567</td>\n",
       "      <td>:Thank you for pointing those issues out. They...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42613</td>\n",
       "      <td>== Trackers Task Force ==</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52416</td>\n",
       "      <td>== isotope discrimination, atmospheric values,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.919413</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45891</td>\n",
       "      <td>, because they're gay</td>\n",
       "      <td>0</td>\n",
       "      <td>0.915953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       comment_text  toxicity  \\\n",
       "0        2732  == Your (re)appointment == \\n\\n You have both ...         0   \n",
       "1       43567  :Thank you for pointing those issues out. They...         0   \n",
       "2       42613                          == Trackers Task Force ==         0   \n",
       "3       52416  == isotope discrimination, atmospheric values,...         0   \n",
       "4       45891                              , because they're gay         0   \n",
       "\n",
       "   supermod_inferred_results  supermod  \n",
       "0                   0.003531         0  \n",
       "1                   0.000595         0  \n",
       "2                   0.047709         0  \n",
       "3                   0.919413         1  \n",
       "4                   0.915953         1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "input_path = \"/data/SuperMod/testfolds/fold\" + str(i) + \".csv\"\n",
    "result_path_hapy = \"/data/SuperMod/infer_result_fold\" + str(i) + \".pkl\"\n",
    "result_path_bert = \"/data/SuperMod/raw/fold\"  + str(i) + \".csv\"\n",
    "bert_df = pd.read_csv(result_path_bert)\n",
    "bert_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42227   , 0.10188487, 0.56421876, 0.08692576, 0.79050314,\n",
       "       0.2410989 , 0.23324262, 0.96217716, 0.7684657 , 0.10649429],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(result_path_hapy, 'rb') as w:\n",
    "    result = pkl.load(w)\n",
    "result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2732</td>\n",
       "      <td>6590</td>\n",
       "      <td>== Your (re)appointment == \\n\\n You have both ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43567</td>\n",
       "      <td>104026</td>\n",
       "      <td>:Thank you for pointing those issues out. They...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42613</td>\n",
       "      <td>101810</td>\n",
       "      <td>== Trackers Task Force ==</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52416</td>\n",
       "      <td>125175</td>\n",
       "      <td>== isotope discrimination, atmospheric values,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45891</td>\n",
       "      <td>109648</td>\n",
       "      <td>, because they're gay</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0        2732          6590   \n",
       "1       43567        104026   \n",
       "2       42613        101810   \n",
       "3       52416        125175   \n",
       "4       45891        109648   \n",
       "\n",
       "                                        comment_text  toxicity  \n",
       "0  == Your (re)appointment == \\n\\n You have both ...         0  \n",
       "1  :Thank you for pointing those issues out. They...         0  \n",
       "2                          == Trackers Task Force ==         0  \n",
       "3  == isotope discrimination, atmospheric values,...         0  \n",
       "4                              , because they're gay         0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df = pd.read_csv(\"/data/SuperMod/testfolds/fold0.csv\")\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62501</td>\n",
       "      <td>149459</td>\n",
       "      <td>\" \\n\\n == Homer's \"\"Official\"\" Age == \\n\\n Acc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33003</td>\n",
       "      <td>78986</td>\n",
       "      <td>== WP:RS == \\n\\n Someone has added a BLOG as a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12172</td>\n",
       "      <td>29233</td>\n",
       "      <td>Being a psychopath I would have to tell you al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5192</td>\n",
       "      <td>12528</td>\n",
       "      <td>DIS NIGGA IS GAY HE KILLED LOTS OF FUQIN PPL T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32511</td>\n",
       "      <td>77820</td>\n",
       "      <td>빨리 차단 해제하라! 그렇지 않으면 범칙금 10만 원이야. 병신아. 차단 빨리 해제하라.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0       62501        149459   \n",
       "1       33003         78986   \n",
       "2       12172         29233   \n",
       "3        5192         12528   \n",
       "4       32511         77820   \n",
       "\n",
       "                                        comment_text  toxicity  \n",
       "0  \" \\n\\n == Homer's \"\"Official\"\" Age == \\n\\n Acc...         0  \n",
       "1  == WP:RS == \\n\\n Someone has added a BLOG as a...         0  \n",
       "2  Being a psychopath I would have to tell you al...         0  \n",
       "3  DIS NIGGA IS GAY HE KILLED LOTS OF FUQIN PPL T...         1  \n",
       "4  빨리 차단 해제하라! 그렇지 않으면 범칙금 10만 원이야. 병신아. 차단 빨리 해제하라.         0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df = pd.read_csv(\"/data/SuperMod/testfolds/fold1.csv\")\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = pd.read_csv(\"/data/SuperMod/testfolds/fold1.csv\")\n",
    "with open('/data/SuperMod/infer_result_fold1.pkl', 'rb') as w:\n",
    "    result2 = pkl.load(w)\n",
    "get_metrics(np.asarray(test1.toxicity), np.asarray(result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/data/SuperMod/testfolds/fold\" + str(i) + \".csv\"\n",
    "result_path = \"/data/SuperMod/infer_result_fold\" + str(i) + \".pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This bash script knows about /data/SuperMod/testfolds/fold49.csv and /data/SuperMod/infer_result_fold49.pkl\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$input_path\" \"$result_path\"\n",
    "echo \"This bash script knows about $1 and $2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-264b95cf9aa7>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-264b95cf9aa7>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    echo \"This bash script knows about $1 and $2\"\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    \n",
    "    input_path = \"/data/SuperMod/testfolds/fold\" + str(i) + \".csv\"\n",
    "    result_path = \"/data/SuperMod/infer_result_fold\" + str(i) + \".pkl\"\n",
    "    \n",
    "    %%bash -s \"$input_path\" \"$result_path\"\n",
    "    echo \"This bash script knows about $1 and $2\"\n",
    "\n",
    "#     !python inference_ha.py -test_path input_path  -out_path '/data/SuperMod/hapy_state_wiki_enr_imdb_4.pth' \\\n",
    "# -infer_result result_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.evaluate import load_dev_labels, get_metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500,)\n",
      "(1500,)\n",
      "True Positives per class :  356\n",
      "False Positives per class :  225\n",
      "False Negatives per class :  66\n",
      "Accuracy : 0.8060, Precision : 0.613, Recall : 0.844, F1 : 0.710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.806, 0.612736660929432, 0.8436018957345972, 0.7098703888334996)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = pd.read_csv(\"/data/SuperMod/testfolds/fold1.csv\")\n",
    "with open('/data/SuperMod/infer_result_fold1.pkl', 'rb') as w:\n",
    "    result2 = pkl.load(w)\n",
    "get_metrics(np.asarray(test1.toxicity), np.asarray(result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
